"""
@author: Katherine Eaton

plague-phylogeography snakemake pipeline.

snakemake --cores 1 --configfile config/snakemake.yaml

"""

# -----------------------------------------------------------------------------#
#                             Modules and Packages                             #
# -----------------------------------------------------------------------------#
import os # Path manipulation

from snakemake.remote.FTP import RemoteProvider as FTPRemoteProvider
FTP = FTPRemoteProvider()
# Enforce minimum version
from snakemake.utils import min_version
min_version("5.26.1")

# -----------------------------------------------------------------------------#
#                                 Setup                                        #
# -----------------------------------------------------------------------------#

project_dir = os.path.dirname(workflow.basedir)
results_dir = os.path.join(project_dir, "results")
scripts_dir = os.path.join(project_dir, "workflow", "scripts")
envs_dir = os.path.join(project_dir, "workflow", "envs")
logs_dir = os.path.join(project_dir, "workflow", "logs")
report_dir = os.path.join(project_dir, "workflow", "report")
rules_dir = os.path.join(project_dir, "workflow", "rules")
config_dir = os.path.join(project_dir, "config")

# Include the config file
configfile: os.path.join(config_dir, "snakemake.yaml")

# Sub snakefiles
include: rules_dir + "/download.smk"
include: rules_dir + "/alignment.smk"
include: rules_dir + "/phylogeny.smk"
include: rules_dir + "/qc.smk"
include: rules_dir + "/filter_mask.smk"
include: rules_dir + "/plot.smk"
include: rules_dir + "/functions.smk"
include: rules_dir + "/targets.smk"

# Report file
report: report_dir + "/workflow.rst"

# -----------------------------------------------------------------------------#
# Package Management                                                           #
# -----------------------------------------------------------------------------#
conda: os.path.join(project_dir, "workflow/envs/main/main.yaml")
container: "docker://ktmeaton/plague-phylogeography"

# -----------------------------------------------------------------------------#
# Environment variables                                               #
# -----------------------------------------------------------------------------#
# Singularity
if workflow.singularity_prefix:
    os.environ["SINGULARITY_CACHEDIR"] =  workflow.singularity_prefix
    os.environ["NXF_SINGULARITY_CACHEDIR"] =  workflow.singularity_prefix
else:
    os.environ["SINGULARITY_CACHEDIR"] = os.path.join(project_dir, ".snakemake", "singularity")
    os.environ["NXF_SINGULARITY_CACHEDIR"] = os.path.join(project_dir, ".snakemake", "singularity")
# Conda
if workflow.conda_prefix:
    os.environ["CONDA_CACHEDIR"] =  workflow.conda_prefix
    os.environ["NXF_CONDA_CACHEDIR"] = workflow.conda_prefix
else:
    os.environ["CONDA_CACHEDIR"] = os.path.join(project_dir, ".snakemake", "conda")
    os.environ["NXF_CONDA_CACHEDIR"] = os.path.join(project_dir, ".snakemake", "conda")
# Locale settings for perl
if "LANGUAGE" not in os.environ:
    os.environ["LANGUAGE"] = "en_US.UTF-8"
if "LANG" not in os.environ:
    os.environ["LANG"] = "en_US.UTF-8"
if "LC_ALL" not in os.environ:
    os.environ["LC_ALL"] = "en_US.UTF-8"

# -----------------------------------------------------------------------------#
# Local rules                                                                  #
# -----------------------------------------------------------------------------#
localrules:
    download_assembly,

# -----------------------------------------------------------------------------#
# Main Target                                                                  #
# -----------------------------------------------------------------------------#
rule all:
    """
    The default pipeline targets.
    """
    input:
        # Multiqc
        results_dir + "/multiqc/multiqc_report.html",
        # IQTREE
        expand(results_dir + "/iqtree/iqtree.core-{locus_name}.filter{missing_data}.treefile",
                            locus_name=config["reference_locus_name"],
                            missing_data=config['snippy_missing_data']),
        # Tables of downloaded data
        results_dir + "/data/assembly/table_assembly_fna.pdf",
        results_dir + "/data/reference/table_reference_fna.pdf",
        results_dir + "/data/local/table_local_fastq-gz.pdf",
        results_dir + "/data/sra/table_sra_fastq-gz.pdf",

# -----------------------------------------------------------------------------#
#                             Help and Usage                                   #
# -----------------------------------------------------------------------------#

rule help:
  """
  Print list of all targets with help.
  """
  run:
    for rule in workflow.rules:
      print("-" * 80)
      print("rule: ", rule.name )
      if rule.docstring:
          print(rule.docstring)
      if rule._input:
          print("\tinput:")
          for in_file in rule.input:
              print("\t\t" + str(in_file))
          for in_file in rule.input.keys():
              print("\t\t" + in_file + ": " + str(rule.input[in_file]))
      if rule._output:
          print("\toutput:")
          for out_file in rule.output:
              print("\t\t" + out_file)
          for out_file in rule.output.keys():
              print("\t\t" + out_file + ": " + str(rule.output[out_file]))
      if rule._params:
          print("\tparams:")
          for param in rule.params.keys():
              print("\t\t" + param + ": " + str(rule.params[param]))
      if rule.resources:
          print("\tresources:")
          for resource in rule.resources.keys():
              print("\t\t" + resource.strip("_") + ": " + str(rule.resources[resource]))
      if rule.conda_env:
          print("\t\tconda: ", rule.conda_env)
      if rule._log:
          print("\t\tlog: ", rule._log)

'''
rule collect:
    """ Collect files from different reads_origin in a rule."""
    input: 
        rule_dir = expand(results_dir + "/{{rule}}/{reads_origin}/{sample}/",
                   reads_origin = config["reads_origin"]),
    output:
        collect_dir = directory(results_dir + "/{rule}/all/"),
        collect_sample = directory(expand(results_dir + "/{{rule}}/all/{sample}/",
				          sample=identify_all_sample())
                                  ),
    shell:
        "for dir in {input.rule_dir}; \
         do \
	   ln -s $dir/* {output.collect_dir}; \
         done; "
'''
