{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "functional-hudson",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "1. Run clock analysis.\n",
    "1. Add clock stats to dataframe.\n",
    "\n",
    "Troubleshooting:\n",
    "  - Disappearing nodes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "herbal-papua",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-atlas",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "joint-worst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Create directories and files\n",
    "import random # Set seed for stats\n",
    "import copy # copy objects to prevent permanent modification\n",
    "\n",
    "# Logging output to file\n",
    "import sys\n",
    "import io\n",
    "\n",
    "# Phylogenetics\n",
    "from Bio import Phylo # Tree operations\n",
    "from Bio import AlignIO # Add constant sites to alignment\n",
    "import treetime # Timetree operations\n",
    "\n",
    "# JSON\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "registered-gospel",
   "metadata": {},
   "source": [
    "## Input File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nervous-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_path = \"../../docs/results/latest/parse_tree/parse_tree.nwk\"\n",
    "tree_df_path = \"../../docs/results/latest/mugration/mugration.tsv\"\n",
    "aln_path = \"../../docs/results/latest/snippy_multi/snippy-core_chromosome.snps.filter5.aln\"\n",
    "constant_sites_path = \"../../docs/results/latest/snippy_multi/snippy-core_chromosome.full.constant_sites.txt\"\n",
    "outdir = \"../../docs/results/latest/timetree/\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-concentrate",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "infrared-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "NAME_COL = \"Name\"\n",
    "SCRIPT_NAME = \"timetree\"\n",
    "\n",
    "# Random\n",
    "random.seed(1152342, 2)\n",
    "np.random.seed(70262122)\n",
    "st0 = np.random.get_state()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "potential-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "align = AlignIO.read(aln_path, format=\"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "agreed-washington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'constant_sites_dict = {\"A\": 0, \"C\" : 0, \"G\" : 0, \"T\" : 0}\\n\\nwith open(constant_sites_path, \"r\") as infile:\\n    constant_sites_list = infile.read().strip().split(\",\")\\n    constant_sites_dict[\"A\"] = int(constant_sites_list[0])\\n    constant_sites_dict[\"C\"] = int(constant_sites_list[1])\\n    constant_sites_dict[\"G\"] = int(constant_sites_list[2])\\n    constant_sites_dict[\"T\"] = int(constant_sites_list[3])    \\n\\nprint(constant_sites_dict)\\ntotal_constant_sites = sum(constant_sites_dict.values())\\nprint(\"Constant Sites:\", total_constant_sites)\\n\\n# Add the constant sites to each sample\\n# Iterate through each samples sequence\\nfor rec in align:\\n    # Iterate through each nucleotide for constant sites\\n    for nucleotide,count in constant_sites_dict.items():\\n        rec.seq = rec.seq + (nucleotide * count)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"constant_sites_dict = {\"A\": 0, \"C\" : 0, \"G\" : 0, \"T\" : 0}\n",
    "\n",
    "with open(constant_sites_path, \"r\") as infile:\n",
    "    constant_sites_list = infile.read().strip().split(\",\")\n",
    "    constant_sites_dict[\"A\"] = int(constant_sites_list[0])\n",
    "    constant_sites_dict[\"C\"] = int(constant_sites_list[1])\n",
    "    constant_sites_dict[\"G\"] = int(constant_sites_list[2])\n",
    "    constant_sites_dict[\"T\"] = int(constant_sites_list[3])    \n",
    "\n",
    "print(constant_sites_dict)\n",
    "total_constant_sites = sum(constant_sites_dict.values())\n",
    "print(\"Constant Sites:\", total_constant_sites)\n",
    "\n",
    "# Add the constant sites to each sample\n",
    "# Iterate through each samples sequence\n",
    "for rec in align:\n",
    "    # Iterate through each nucleotide for constant sites\n",
    "    for nucleotide,count in constant_sites_dict.items():\n",
    "        rec.seq = rec.seq + (nucleotide * count)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-charge",
   "metadata": {},
   "source": [
    "## Import Divergence Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-potter",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_div = Phylo.read(tree_path, \"newick\")\n",
    "tree_div.ladderize(reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-worship",
   "metadata": {},
   "source": [
    "## Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "awful-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df = pd.read_csv(tree_df_path, sep='\\t')\n",
    "# Fix the problem with multiple forms of NA in the table\n",
    "# Consolidate missing data to the NO_DATA_CHAR\n",
    "tree_df.fillna(NO_DATA_CHAR, inplace=True)\n",
    "tree_df.set_index(NAME_COL, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-russell",
   "metadata": {},
   "source": [
    "## Remove Bad Branches\n",
    "\n",
    "Identified in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-costume",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOT FIX for bad branches\n",
    "tmp_tree = os.path.join(outdir, \"temp.nwk\")\n",
    "\n",
    "bad_samples = [\"GCA_008630375.1_ASM863037v1_genomic\", \n",
    "                \"GCA_008630375.2_ASM863037v2_genomic\", \n",
    "                \"GCA_003086075.1_ASM308607v1_genomic\",\n",
    "                \"GCA_001613865.1_ASM161386v1_genomic\"]\n",
    "\n",
    "# Prune bad samples from tree and dataframe\n",
    "for sample in bad_samples:\n",
    "    tree_div.prune(sample)\n",
    "    tree_df.drop(index=sample, inplace=True)\n",
    "    \n",
    "# Save temp files\n",
    "tmp_path_df = os.path.join(outdir, SCRIPT_NAME + \".tsv\" )\n",
    "tree_df.to_csv(tmp_path_df, sep=\"\\t\")\n",
    "\n",
    "tmp_path_nwk = os.path.join(outdir, SCRIPT_NAME + \".nwk\" )\n",
    "Phylo.write(tree_div, tmp_path_nwk, 'newick', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-premium",
   "metadata": {},
   "source": [
    "## Intialize Timetree Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-laser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the utils function to parse the metadata dates\n",
    "dates_raw = treetime.utils.parse_dates(tmp_path_df, \n",
    "                                   date_col=DATE_COL, \n",
    "                                   name_col = NAME_COL)\n",
    "\n",
    "# Remove nan elements (internal nodes)\n",
    "dates = {}\n",
    "for k,v in dates_raw.items():\n",
    "    if type(v) == list:\n",
    "        dates[k] = v\n",
    "    elif not pd.isnull(v):\n",
    "        dates[k] = v\n",
    "\n",
    "# Construct the treetime object\n",
    "# Remember, including the alignment is crucial!\n",
    "tt = treetime.TreeTime(dates=dates, \n",
    "                       aln=aln_path,                     \n",
    "                       tree=tmp_path_nwk, \n",
    "                       verbose=4, \n",
    "                       fill_overhangs=False,\n",
    "                       seq_len=REF_LEN,                        \n",
    "                      )\n",
    "\n",
    "# Remove outliers\n",
    "tt.clock_filter(reroot=None, \n",
    "                n_iqd=N_IQD, \n",
    "                plot=True,\n",
    "               )\n",
    "\n",
    "# Check rtt\n",
    "print(tt.date2dist.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-disaster",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Clock Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stdout capture\n",
    "# old_stdout = sys.stdout\n",
    "# new_stdout = io.StringIO()\n",
    "# sys.stdout = new_stdout\n",
    "\n",
    "# PARAM MIN: root='-4101-09-02'\n",
    "#tt.run()\n",
    "\n",
    "#tt.run(time_marginal=TIME_MARGINAL)\n",
    "\n",
    "# PARAM FULL: root=''\n",
    "tt.run(\n",
    "       Tc=\"skyline\", \n",
    "       max_iter=MAX_ITER,\n",
    "       relaxed_clock={\"slack\":5.0, \"coupling\": 0},\n",
    "       infer_gtr=True,\n",
    "       time_marginal=TIME_MARGINAL,\n",
    "       sequence_marginal=SEQ_MARGINAL,\n",
    "       verbose=4,\n",
    "       resolve_polytomies=False,\n",
    "       n_iqd=N_IQD,\n",
    "       # branch_length_mode = \"input\",\n",
    "       # root=None,\n",
    "       # use_covariation=False,\n",
    "       # vary_rate=False,\n",
    "       )\n",
    "\n",
    "# Save stdout to file\n",
    "# output = new_stdout.getvalue()\n",
    "# out_path = os.path.join(outdir, SCRIPT_NAME + \".log\") \n",
    "# with open(out_path, \"w\") as file:\n",
    "#     file.write(output)\n",
    "# # Restore stdout\n",
    "# sys.stdout = old_stdout\n",
    "# print(\"Standard output restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check 1\n",
    "tt.tree.common_ancestor(\"NODE0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check 2\n",
    "tt.clock_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-power",
   "metadata": {},
   "source": [
    "## Ladderize Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tree.ladderize(reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-stadium",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Add clock stats to data frame\n",
    "\n",
    "- Rates\n",
    "- Dates\n",
    "- RTT Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-jamaica",
   "metadata": {},
   "source": [
    "## Rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-speed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df[\"timetree_rate\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_rate_fold_change\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_mutation_length\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "\n",
    "# The mean rate is the slope\n",
    "mean_rate = tt.clock_model[\"slope\"]\n",
    "\n",
    "for c in tt.tree.find_clades():\n",
    "    tree_df.at[c.name, \"timetree_mutation_length\"] = c.mutation_length\n",
    "    \n",
    "    # Relaxed Clock\n",
    "    if hasattr(c, \"branch_length_interpolator\") and c.branch_length_interpolator:\n",
    "        g = c.branch_length_interpolator.gamma\n",
    "        tree_df.at[c.name, \"timetree_rate_fold_change\"] = g\n",
    "        tree_df.at[c.name, \"timetree_rate\"] = mean_rate * g\n",
    "        \n",
    "    # Strict Clock\n",
    "    else:\n",
    "        tree_df.at[c.name, \"timetree_rate_fold_change\"] = 1\n",
    "        tree_df.at[c.name, \"timetree_rate\"] = mean_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-auckland",
   "metadata": {},
   "source": [
    "## Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns\n",
    "tree_df[\"timetree_date\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_numdate\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "\n",
    "# Optional confidence intervals if marginal prob was run\n",
    "tree_df[\"timetree_numdate_lower\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_numdate_upper\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "\n",
    "# clock_length is the same as branch_length until running branch_length_to_years()\n",
    "tree_df[\"timetree_clock_length\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "\n",
    "# Make a copy to change branch_length\n",
    "tt_copy = copy.deepcopy(tt)\n",
    "tt_copy.branch_length_to_years()\n",
    "\n",
    "for c in tt_copy.tree.find_clades():\n",
    "    # Marginal Probability\n",
    "    if hasattr(c, \"marginal_inverse_cdf\"):    \n",
    "        # Retrieve the region containing the confidence interval\n",
    "        conf = tt.get_max_posterior_region(c, fraction=CONFIDENCE) \n",
    "        \n",
    "        # Set as lower and upper bounds on date\n",
    "        tree_df.at[c.name, \"timetree_numdate_lower\"] = conf[0]\n",
    "        tree_df.at[c.name, \"timetree_numdate_upper\"] = conf[1]\n",
    "\n",
    "    tree_df.at[c.name, \"timetree_date\"] = c.date  \n",
    "    tree_df.at[c.name, \"timetree_numdate\"] = c.numdate\n",
    "    tree_df.at[c.name, \"timetree_clock_length\"] = c.branch_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-gasoline",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a copy of the tree\n",
    "tt_copy = copy.deepcopy(tt)\n",
    "tt_copy.branch_length_to_years()\n",
    "\n",
    "# Plotting the tree\n",
    "tree_df[\"timetree_coord_x\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_coord_y\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))] \n",
    "\n",
    "# Plotting the regression\n",
    "tree_df[\"timetree_reg_x\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_reg_y\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_reg_bad\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "\n",
    "x_posns = get_x_positions(tt_copy.tree)\n",
    "y_posns = get_y_positions(tt_copy.tree)\n",
    "tt_reg = tt_copy.setup_TreeRegression()\n",
    "\n",
    "# Add x and y coordinates\n",
    "for c in tt_copy.tree.find_clades():     \n",
    "        \n",
    "    # Tree Node Coordinates\n",
    "    coord_x = [value for key,value in x_posns.items() if key.name == c.name][0]\n",
    "    coord_y = [value for key,value in y_posns.items() if key.name == c.name][0]\n",
    "    tree_df.at[c.name, 'timetree_coord_x'] = coord_x\n",
    "    tree_df.at[c.name, 'timetree_coord_y'] = coord_y\n",
    "    \n",
    "    # Regression Node Coordinates\n",
    "    reg_y = c._v\n",
    "    if c.is_terminal():\n",
    "        reg_x = tt_reg.tip_value(c)\n",
    "    else:\n",
    "        reg_x = c.numdate\n",
    "    reg_bad = c.bad_branch  if hasattr(c, 'bad_branch') else False\n",
    "    tree_df.at[c.name, 'timetree_reg_x'] = reg_x\n",
    "    tree_df.at[c.name, 'timetree_reg_y'] = reg_y    \n",
    "    tree_df.at[c.name, 'timetree_reg_bad'] = reg_bad\n",
    "\n",
    "# Fix up new values that could be none\n",
    "tree_df.fillna(NO_DATA_CHAR, inplace=True)\n",
    "tree_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-customs",
   "metadata": {},
   "source": [
    "---\n",
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-namibia",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tree dataframe with clock info\n",
    "out_path_df = os.path.join(outdir, SCRIPT_NAME + \".tsv\" )\n",
    "tree_df.to_csv(out_path_df, sep=\"\\t\")\n",
    "\n",
    "# Save timetree trees\n",
    "out_path_xml = os.path.join(outdir, SCRIPT_NAME + \".xml\" )\n",
    "out_path_nwk = os.path.join(outdir, SCRIPT_NAME + \".nwk\" )\n",
    "out_path_nexus = os.path.join(outdir, SCRIPT_NAME + \".nexus\" )\n",
    "Phylo.write(tt.tree, out_path_xml, 'phyloxml')\n",
    "Phylo.write(tt.tree, out_path_nwk, 'newick', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))\n",
    "Phylo.write(tt.tree, out_path_nexus, 'nexus', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-inspector",
   "metadata": {},
   "source": [
    "## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "clock_model_dict = {}\n",
    "keys = [\"slope\", \"intercept\", \"chisq\", \"r_val\"]\n",
    "for k in keys:\n",
    "    clock_model_dict[k] = tt.clock_model[k]\n",
    "\n",
    "out_path_json = os.path.join(outdir, SCRIPT_NAME + \"_clock_model.json\" )\n",
    "with open(out_path_json, \"w\") as outfile:  \n",
    "    json.dump(clock_model_dict, outfile, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-title",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
