{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dominant-revolution",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "1. Animated Subtree\n",
    "\n",
    "1. Sampling Bias\n",
    "    - A. Full\n",
    "    - B. Russia \"Knockout\"\n",
    "    - C. Germany \"Knockout\"\n",
    "1. Geocoding Bias\n",
    "1. Drawing Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-consensus",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-teaching",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-farmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dill\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from Bio import Phylo\n",
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "from matplotlib import lines, patheffects, animation, gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-exception",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "# Custom script variables\n",
    "SCRIPT_NAME = \"geo\"\n",
    "PREV_DIR_NAME = \"mugration\"\n",
    "PREV_SCRIPT_NAME = \"mugration_model\"\n",
    "\n",
    "try:\n",
    "    WILDCARDS = snakemake.wildcards\n",
    "    project_dir = os.getcwd()\n",
    "except NameError:\n",
    "    WILDCARDS = [\"all\", \"chromosome\", \"5\"]\n",
    "    project_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "    \n",
    "READS_ORIGIN = WILDCARDS[0]\n",
    "LOCUS_NAME = WILDCARDS[1]\n",
    "MISSING_DATA = WILDCARDS[2]\n",
    "\n",
    "BASEMAP = cimgt.Stamen('terrain-background')\n",
    "NAME_COL = \"Name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "victorian-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['config'])\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-opinion",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-hardware",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = os.path.join(project_dir, \"config\")\n",
    "results_dir = os.path.join(project_dir, \"results\")\n",
    "\n",
    "outdir       = os.path.join(results_dir, SCRIPT_NAME, READS_ORIGIN, LOCUS_NAME + \"_filter{}\".format(MISSING_DATA),)\n",
    "#tree_dill    = os.path.join(results_dir, PREV_DIR_NAME, READS_ORIGIN, LOCUS_NAME + \"_filter{}\".format(MISSING_DATA),PREV_SCRIPT_NAME + \"_timetree.treetime.obj\")\n",
    "#tree_df_dill = os.path.join(results_dir, PREV_DIR_NAME, READS_ORIGIN, LOCUS_NAME + \"_filter{}\".format(MISSING_DATA), PREV_SCRIPT_NAME + \".df.obj\")\n",
    "tree_path    = os.path.join(results_dir, PREV_DIR_NAME, READS_ORIGIN, LOCUS_NAME + \"_filter{}\".format(MISSING_DATA), PREV_SCRIPT_NAME + \"_timetree.nwk\")\n",
    "tree_df_path = os.path.join(results_dir, PREV_DIR_NAME, READS_ORIGIN, LOCUS_NAME + \"_filter{}\".format(MISSING_DATA), PREV_SCRIPT_NAME + \".tsv\")\n",
    "aln_path     = os.path.join(results_dir,\"snippy_multi\",READS_ORIGIN,\"snippy-core_{}.snps.filter{}.aln\".format(LOCUS_NAME, MISSING_DATA))\n",
    "\n",
    "# Auspice\n",
    "auspice_latlon_path = os.path.join(results_dir, \"parse_tree\", READS_ORIGIN, LOCUS_NAME + \"_filter{}\".format(MISSING_DATA), \"parse_tree\" + \"_latlon.tsv\")\n",
    "auspice_colors_path = os.path.join(results_dir, \"parse_tree\", READS_ORIGIN, LOCUS_NAME + \"_filter{}\".format(MISSING_DATA), \"parse_tree\" + \"_colors.tsv\")\n",
    "auspice_config_path = os.path.join(config_dir, \"auspice_config.json\")\n",
    "auspice_remote_dir_path = os.path.join(project_dir, \"auspice/\")\n",
    "\n",
    "#print(\"tree_dill:\\t\", tree_dill)\n",
    "#print(\"tree_df_dill:\\t\", tree_df_dill)\n",
    "print(\"aln path:\\t\", aln_path)\n",
    "print(\"auspice_latlon_path:\", auspice_latlon_path)\n",
    "print(\"auspice_colors_path:\", auspice_colors_path)\n",
    "print(\"auspice_config_path:\", auspice_config_path)\n",
    "print(\"auspice_remote_dir_path:\", auspice_remote_dir_path)\n",
    "print(\"outdir:\", outdir)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "while not os.path.exists(outdir):\n",
    "    os.makedirs(outdir)   \n",
    "    \n",
    "SCRIPT_NAME = \"geo_animate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "isolated-holiday",
   "metadata": {},
   "source": [
    "## Import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(tree_dill, \"rb\") as infile:\n",
    "#     tt = dill.load(infile)\n",
    "# tt.tree.ladderize(reverse=False)\n",
    "\n",
    "tree = Phylo.read(tree_path, \"newick\")\n",
    "tree.ladderize(reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-daily",
   "metadata": {},
   "source": [
    "## Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-kingston",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(tree_df_dill, \"rb\") as infile:\n",
    "#     tree_df = dill.load(infile)\n",
    "# display(tree_df)\n",
    "\n",
    "tree_df = pd.read_csv(tree_df_path, sep='\\t')\n",
    "tree_df.fillna(NO_DATA_CHAR, inplace=True)\n",
    "tree_df.set_index(NAME_COL, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-stream",
   "metadata": {},
   "source": [
    "# Import Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_df = pd.read_csv(auspice_colors_path, sep='\\t', header=None)\n",
    "colors_df.columns = [\"Attribute\", \"State\", \"Color\"]\n",
    "colors_df.fillna(NO_DATA_CHAR, inplace=True)\n",
    "\n",
    "# Add sizes\n",
    "colors_df[\"Size\"] = [NO_DATA_CHAR for i in range(0,len(colors_df))]\n",
    "i = 0\n",
    "for attr in list(dict.fromkeys(colors_df[\"Attribute\"])):\n",
    "    title_attr = attr.replace(\"_\",\" \").title().replace(\" \",\"_\")\n",
    "    attr_df =  colors_df[colors_df[\"Attribute\"] == attr]\n",
    "    for state in attr_df[\"State\"]:\n",
    "        if attr == \"branch_number\":\n",
    "            state = int(state)\n",
    "        matches = tree_df[tree_df[title_attr] == state]\n",
    "        colors_df.at[i,\"Size\"] = len(matches)\n",
    "        i += 1\n",
    "\n",
    "display(colors_df)\n",
    "    \n",
    "# Convert to dict\n",
    "colors_dict = {}\n",
    "sizes_dict = {}\n",
    "for rec in colors_df.iterrows():\n",
    "    attr = rec[1][\"Attribute\"]\n",
    "    state = rec[1][\"State\"]\n",
    "    color = rec[1][\"Color\"]\n",
    "    size = rec[1][\"Size\"]\n",
    "\n",
    "    if attr not in colors_dict:\n",
    "        colors_dict[attr] = {}\n",
    "    if attr not in sizes_dict:\n",
    "        sizes_dict[attr] = {}        \n",
    "    colors_dict[attr][state] = color        \n",
    "    sizes_dict[attr][state] = size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-weekend",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Animate Subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-webcam",
   "metadata": {},
   "outputs": [],
   "source": [
    "branch   = \"1.PRE\"\n",
    "geo_attr = \"Province\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuing-flush",
   "metadata": {},
   "source": [
    "## Create Subtree and Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "clade_df = tree_df[tree_df[\"Mugration_Branch_Major\"] == branch]\n",
    "clade = tree.common_ancestor(clade_df.index)\n",
    "parent_node = copy.deepcopy(get_parent(tree, clade.root.name))\n",
    "parent_rec = tree_df[tree_df.index.str.contains(parent_node.name)]\n",
    "clade = parent_node\n",
    "clade_df = clade_df.append(parent_rec)\n",
    "\n",
    "# Prune clades outside\n",
    "prune_nodes = []\n",
    "\n",
    "for c in clade.find_clades(order=\"postorder\"):\n",
    "    if c.name not in clade_df.index:\n",
    "        prune_nodes.append(c)\n",
    "        \n",
    "for node in prune_nodes:\n",
    "    if node in clade.find_clades(node):\n",
    "        try:\n",
    "            clade.prune(node)\n",
    "        except AttributeError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "# Clean up dataframe\n",
    "for node in clade_df.index:\n",
    "    if node not in [c.name for c in clade.find_clades()]:\n",
    "        clade_df.drop(node, inplace=True)\n",
    "\n",
    "\n",
    "display(clade_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-affair",
   "metadata": {},
   "source": [
    "## Convert Dataframe to Geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-spotlight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframe to geopandas\n",
    "geometry = []\n",
    "for rec in clade_df.iterrows():\n",
    "    sample = rec[0]\n",
    "    x = clade_df[\"Mugration_\" + geo_attr + \"_Lon\"][sample] \n",
    "    y = clade_df[\"Mugration_\" + geo_attr + \"_Lat\"][sample]\n",
    "    geometry.append(shapely.geometry.Point(x,y))\n",
    "\n",
    "clade_gdf = geopandas.GeoDataFrame(clade_df, crs=CRS, geometry=geometry)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-prospect",
   "metadata": {},
   "source": [
    "## Add Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Root Data\n",
    "root_geom = clade_gdf[\"geometry\"][clade.root.name]\n",
    "root_date = clade_gdf[\"timetree_num_date\"][clade.root.name]\n",
    "root_state = clade_df[\"Mugration_Branch_Major\"][clade.root.name]\n",
    "root_color = colors_dict[\"branch_major\"][root_state] \n",
    "root_marker = lines.Line2D([root_geom.x], \n",
    "            [root_geom.y],\n",
    "            marker=\"*\",\n",
    "            markerfacecolor=root_color, \n",
    "            markeredgecolor=\"black\", \n",
    "            markeredgewidth=0.5,\n",
    "            markersize=10, \n",
    "            zorder=4,\n",
    "        )\n",
    "# ---------------------------------------\n",
    "# Node and Connections Data\n",
    "network = tree2network(clade)\n",
    "network_connections = []\n",
    "node_markers = []\n",
    "\n",
    "for connection in network:\n",
    "    # Node names\n",
    "    origin_name = connection[0].name\n",
    "    dest_name = connection[1].name\n",
    "    \n",
    "    # Node Geometry\n",
    "    origin_geom = clade_gdf[\"geometry\"][origin_name]\n",
    "    dest_geom = clade_gdf[\"geometry\"][dest_name]\n",
    "    \n",
    "    # Aesthetic\n",
    "    dest_state = clade_gdf[\"Mugration_Branch_Major\"][dest_name]\n",
    "    dest_color = colors_dict[\"branch_major\"][dest_state] \n",
    "    dest_confidence = clade_gdf[\"Mugration_\" + geo_attr + \"_Confidence\"][dest_name]\n",
    "    dest_geo   = clade_df[\"Mugration_\" + geo_attr][dest_name]\n",
    "    dest_size  = sizes_dict[geo_attr.lower()][dest_geo]     \n",
    "            \n",
    "    if dest_confidence < MUG_CONF_THRESH:\n",
    "        dest_color = \"white\"\n",
    "    \n",
    "    # Create the connection line\n",
    "    if origin_geom != dest_geom:        \n",
    "        connection = lines.Line2D(\n",
    "           [origin_geom.x, dest_geom.x], \n",
    "           [origin_geom.y, dest_geom.y],  \n",
    "           color=dest_color,\n",
    "           lw=1.5,\n",
    "           #transform=ccrs.Geodetic(),\n",
    "           path_effects=[\n",
    "               patheffects.Stroke(linewidth=2, foreground='black'),\n",
    "               patheffects.Normal(),\n",
    "           ],\n",
    "           zorder=2,\n",
    "           label=\"{},{}\".format(origin_name, dest_name),\n",
    "        )        \n",
    "        network_connections.append(connection) \n",
    "        #network_connect_uniq.append([origin_geom, dest_geom])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-seven",
   "metadata": {},
   "source": [
    "## Animate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-marathon",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = math.floor(min(clade_df[\"timetree_num_date\"]))\n",
    "min_date = int(math.floor(min_date / 100.0)) * 100\n",
    "\n",
    "max_date = math.ceil(max(clade_df[\"timetree_num_date\"]))\n",
    "max_date = int(math.ceil(max_date / 100.0)) * 100\n",
    "tick_step = 100\n",
    "frame_step = 5\n",
    "time_xticks = range(min_date, max_date + 1, tick_step)\n",
    "animate_frames = range(min_date, max_date + 1, frame_step)\n",
    "# Keys are frames\n",
    "\n",
    "animate_dict = {}\n",
    "for i in range(0,len(animate_frames)):\n",
    "    animate_dict[i] = animate_frames[i]\n",
    "\n",
    "total_frames = len(animate_dict)\n",
    "fps = int(100 / frame_step) # frames per second\n",
    "speed = 1\n",
    "spf = 1000 / (fps * speed) # (milli)seconds per frame\n",
    "\n",
    "print(min_date, max_date, tick_step)\n",
    "#print(animate_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressive-attraction",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "fig_maptime = plt.figure()\n",
    "gs          = gridspec.GridSpec(2, 1, figure=fig_maptime, \n",
    "                                wspace=0, \n",
    "                                hspace=-0.5, \n",
    "                                height_ratios=[20, 1])\n",
    "ax_map      = fig_maptime.add_subplot(gs[0, 0], projection=ccrs.PlateCarree())\n",
    "ax_time     = fig_maptime.add_subplot(gs[1, 0])\n",
    "\n",
    "# Customize Map Axis\n",
    "#ax_map.add_image(BASEMAP, 4)\n",
    "world_polygons.plot(ax=ax_map, color=\"grey\", alpha=0.5, ec=\"black\", lw=0.5)\n",
    "mb = Polygon(clade_gdf['geometry']).bounds\n",
    "xb, yb = 10, 8\n",
    "map_bounds = [mb[0] - xb, mb[2] + xb, mb[1] - yb, mb[3] + yb]\n",
    "ax_map.set_extent(map_bounds, crs=ccrs.PlateCarree()) \n",
    "\n",
    "# Customize Time Axis\n",
    "ax_time.set_xticks(time_xticks)\n",
    "ax_time.set_xlim(min_date, max_date)\n",
    "ax_time.set_ylim(0,0.1)\n",
    "ax_time.set_yticks([])\n",
    "[ax_time.axvline(x, color=\"black\", alpha=1) for x in time_xticks]\n",
    "\n",
    "time_line = ax_time.axvline(x=0, color='grey', lw=5, alpha=0.75)\n",
    "\n",
    "def animate_init():\n",
    "    time_line.set_data([],[])\n",
    "    return time_line,\n",
    "\n",
    "def animate_update(frame, progressive=False):\n",
    "    frame_date = animate_dict[frame]\n",
    "\n",
    "    # Timeline animation\n",
    "    time_line.set_data([frame_date,frame_date], [0,1])\n",
    "            \n",
    "    # Check for connections\n",
    "    for connection in network_connections: \n",
    "        origin_name = connection.get_label().split(\",\")[0]\n",
    "        origin_date = clade_df[\"timetree_num_date\"][origin_name]\n",
    "        dest_name = connection.get_label().split(\",\")[1]\n",
    "        dest_date = clade_df[\"timetree_num_date\"][dest_name]\n",
    "        dest_geom = clade_gdf[\"geometry\"][dest_name]\n",
    "        dest_geo   = clade_df[\"Mugration_\" + geo_attr][dest_name]\n",
    "        dest_size  = sizes_dict[geo_attr.lower()][dest_geo] \n",
    "        \n",
    "        # Plot the root\n",
    "        if frame == 0:\n",
    "            ax_map.add_line(copy.copy(root_marker))\n",
    "        # This marker will be plotted in future animation\n",
    "        if origin_date > frame_date: continue\n",
    "       \n",
    "        num_seg = math.ceil((dest_date - origin_date) / frame_step) \n",
    "        date_seg_delta = (dest_date - origin_date)/ num_seg\n",
    "        \n",
    "        marker = lines.Line2D([dest_geom.x], \n",
    "                [dest_geom.y],\n",
    "                marker=\"o\",\n",
    "                markerfacecolor=dest_color, \n",
    "                markeredgecolor=\"black\", \n",
    "                markeredgewidth=0.5,\n",
    "                markersize=dest_size, \n",
    "                zorder=3,\n",
    "                label=dest_name,                              \n",
    "            )\n",
    "                \n",
    "        # Option 1) Non-Progressive Lines\n",
    "        if not progressive or num_seg <= 1:\n",
    "            if dest_date <= frame_date:\n",
    "                # Check if it was previously plotted\n",
    "                if dest_date > animate_dict[frame - 1]:\n",
    "                    ax_map.add_line(copy.copy(connection)) \n",
    "                    \n",
    "        # Option 2) Progressive Lines\n",
    "        else:\n",
    "            conn_seg = segment_line(connection, num_seg, cumulative=True)\n",
    "            for i in range(1,len(conn_seg) + 1):\n",
    "                seg_date = origin_date + (date_seg_delta * i)\n",
    "                if seg_date <= frame_date:\n",
    "                    ax_map.add_line(copy.copy(conn_seg[i - 1]))\n",
    "                        \n",
    "        # Add Markers\n",
    "        if dest_date > frame_date: continue\n",
    "        # Check if it was previously plotted\n",
    "        if dest_date <= animate_dict[frame - 1]: continue\n",
    "        ax_map.add_line(copy.copy(marker))                \n",
    "                                                 \n",
    "    return time_line,\n",
    "\n",
    "#animate_init()\n",
    "#for i in range(0,1):\n",
    "#     animate_update(i, progressive=True)\n",
    "\n",
    "print(\"Animation will be {} frames.\".format(len(animate_dict)))\n",
    "ani = animation.FuncAnimation(\n",
    "    fig=fig_maptime, \n",
    "    func=animate_update,\n",
    "    fargs=(True,),\n",
    "    init_func=animate_init,\n",
    "    interval=spf,\n",
    "    #frames=len(animate_dict), \n",
    "    frames=20,\n",
    "    blit=True,\n",
    "    repeat=True\n",
    "    )\n",
    "\n",
    "# ani.save('maptime.gif', writer=\"imagemagick\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unusual-circulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "importlib.reload(sys.modules['config'])\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-magnitude",
   "metadata": {},
   "source": [
    "---\n",
    "# Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-origin",
   "metadata": {},
   "source": [
    "## Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_df = os.path.join(outdir, SCRIPT_NAME + \".tsv\" )\n",
    "out_path_pickle_df = os.path.join(outdir,  SCRIPT_NAME + \".df.obj\" )\n",
    "\n",
    "tree_df.to_csv(out_path_df, sep=\"\\t\")\n",
    "with open(out_path_pickle_df,\"wb\") as outfile:\n",
    "    dill.dump(tree_df, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-enhancement",
   "metadata": {},
   "source": [
    "## Timetrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excess-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phyloxml\n",
    "tt_copy = copy.deepcopy(tt)\n",
    "out_path_xml = os.path.join(outdir,  SCRIPT_NAME + \"_timetree.xml\" )\n",
    "Phylo.write(tt_copy.tree, out_path_xml, 'phyloxml')\n",
    "\n",
    "# Nexus\n",
    "out_path_nexus = os.path.join(outdir, SCRIPT_NAME + \"_timetree.nexus\" )\n",
    "Phylo.write(tt_copy.tree, out_path_nexus, 'nexus', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))\n",
    "\n",
    "# Dill object\n",
    "out_path_dill_tree = os.path.join(outdir,  SCRIPT_NAME + \"_timetree.treetime.obj\" )\n",
    "with open(out_path_dill_tree,\"wb\") as outfile:\n",
    "    dill.dump(tt_copy, outfile)\n",
    "    \n",
    "# Newick (remove comments)\n",
    "for c in tt_copy.tree.find_clades(): c.comment = None\n",
    "out_path_nwk = os.path.join(outdir, SCRIPT_NAME + \"_timetree.nwk\" )\n",
    "Phylo.write(tt_copy.tree, out_path_nwk, 'newick', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-arcade",
   "metadata": {},
   "source": [
    "## Divtrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expected-ballet",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_copy = copy.deepcopy(tt)\n",
    "# Convert to divtree\n",
    "for n in tt_copy.tree.find_clades():\n",
    "    n.branch_length=n.mutation_length\n",
    "\n",
    "# Phyloxml\n",
    "out_path_xml = os.path.join(outdir,  SCRIPT_NAME + \"_divtree.xml\" )\n",
    "Phylo.write(tt_copy.tree, out_path_xml, 'phyloxml')\n",
    "\n",
    "# Nexus\n",
    "out_path_nexus = os.path.join(outdir, SCRIPT_NAME + \"_divtree.nexus\" )\n",
    "Phylo.write(tt_copy.tree, out_path_nexus, 'nexus', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))\n",
    "\n",
    "# Dill object\n",
    "out_path_dill_tree = os.path.join(outdir,  SCRIPT_NAME + \"_divtree.treetime.obj\" )\n",
    "with open(out_path_dill_tree,\"wb\") as outfile:\n",
    "    dill.dump(tt_copy, outfile)\n",
    "    \n",
    "# Newick (remove comments)\n",
    "for c in tt_copy.tree.find_clades(): c.comment = None\n",
    "out_path_nwk = os.path.join(outdir, SCRIPT_NAME + \"_divtree.nwk\" )\n",
    "Phylo.write(tt_copy.tree, out_path_nwk, 'newick', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-trunk",
   "metadata": {},
   "source": [
    "## Augur JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "augur_dict = augur_export(\n",
    "    tree_path=out_path_nwk, \n",
    "    aln_path=aln_path, \n",
    "    tree=tt_copy.tree, \n",
    "    tree_df=tree_df, \n",
    "    color_keyword_exclude=[\"color\", \"coord\", \"lat\", \"lon\"],\n",
    "    type_convert = {\n",
    "        \"Branch_Number\" : (lambda x : str(x))\n",
    "    },\n",
    ")\n",
    "\n",
    "print(augur_dict[\"nodes\"][\"NODE0\"])\n",
    "\n",
    "out_path_augur_json = os.path.join(outdir, SCRIPT_NAME + \"_augur.json\" )\n",
    "utils.write_json(data=augur_dict, file_name=out_path_augur_json, indent=JSON_INDENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-hurricane",
   "metadata": {},
   "source": [
    "## Auspice JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-startup",
   "metadata": {},
   "outputs": [],
   "source": [
    "auspice_dict = auspice_export(\n",
    "    tree=tt_copy.tree, \n",
    "    augur_json_paths=[out_path_augur_json], \n",
    "    auspice_config_path=auspice_config_path, \n",
    "    auspice_colors_path=auspice_colors_path,\n",
    "    auspice_latlons_path=auspice_latlon_path, \n",
    "    )\n",
    "\n",
    "# Write outputs - For Local Rendering\n",
    "out_path_auspice_local_json = os.path.join(outdir, SCRIPT_NAME + \"_auspice.json\" )\n",
    "utils.write_json(data=auspice_dict, file_name=out_path_auspice_local_json, indent=JSON_INDENT, include_version=False)\n",
    "export_v2.validate_data_json(out_path_auspice_local_json)\n",
    "print(\"Validation successful for local JSON.\")\n",
    "\n",
    "# Write outputs - For Remote Rendering\n",
    "out_path_auspice_remote_json = os.path.join(auspice_remote_dir_path, AUSPICE_PREFIX + SCRIPT_NAME.replace(\"_\",\"-\") + \".json\" )\n",
    "utils.write_json(data=auspice_dict, file_name=out_path_auspice_remote_json, indent=JSON_INDENT, include_version=False)\n",
    "export_v2.validate_data_json(out_path_auspice_remote_json)\n",
    "print(\"Validation successful for remote JSON.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
