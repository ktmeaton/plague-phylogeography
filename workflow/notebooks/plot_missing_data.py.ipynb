{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "reverse-notification",
   "metadata": {},
   "source": [
    "# Plot Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-effort",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "genetic-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-recognition",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "renewable-snapshot",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/c/Users/ktmea/Projects/plague-phylogeography/results/snippy_multi/all/chromosome/prune/filter0/snippy-multi.snps.log', '/mnt/c/Users/ktmea/Projects/plague-phylogeography/results/snippy_multi/all/chromosome/prune/filter10/snippy-multi.snps.log', '/mnt/c/Users/ktmea/Projects/plague-phylogeography/results/snippy_multi/all/chromosome/prune/filter15/snippy-multi.snps.log', '/mnt/c/Users/ktmea/Projects/plague-phylogeography/results/snippy_multi/all/chromosome/prune/filter20/snippy-multi.snps.log', '/mnt/c/Users/ktmea/Projects/plague-phylogeography/results/snippy_multi/all/chromosome/prune/filter25/snippy-multi.snps.log', '/mnt/c/Users/ktmea/Projects/plague-phylogeography/results/snippy_multi/all/chromosome/prune/filter5/snippy-multi.snps.log']\n"
     ]
    }
   ],
   "source": [
    "filter_logs = []\n",
    "plot_thresholds_list = []\n",
    "reads_origin_list = [\"assembly\", \"sra\", \"local\", \"all\"]\n",
    "\n",
    "\n",
    "# Figure out the project directory\n",
    "try:\n",
    "    snakemake.input.filter_snp_log\n",
    "    project_dir = os.getcwd()\n",
    "    # Figure out reads origin\n",
    "    print(snakemake.wildcards)\n",
    "    reads_origin = snakemake.wildcards.reads_origin\n",
    "    locus_name = snakemake.wildcards.locus_name\n",
    "    prune = snakemake.wildcards.prune\n",
    "    # Figure out locus\n",
    "except NameError:\n",
    "    # Testing outside snakemake\n",
    "    project_dir = os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "    reads_origin = \"all\"\n",
    "    locus_name = \"chromosome\"\n",
    "    prune = \"prune\"\n",
    "    \n",
    "output_dir = os.path.join(project_dir, \"results\", \"snippy_multi\", reads_origin, locus_name, prune)\n",
    "\n",
    "# Get the list of log files\n",
    "try:\n",
    "    filter_logs = [log for log in snakemake.input.filter_snp_log]\n",
    "except NameError:\n",
    "    filter_logs = []\n",
    "    for filter_dir in os.listdir(output_dir):\n",
    "        filter_dir_path = os.path.join(output_dir, filter_dir)\n",
    "        if not os.path.isdir(filter_dir_path): continue\n",
    "        for log in os.listdir(filter_dir_path):\n",
    "            log_path = os.path.join(filter_dir_path, log)\n",
    "            if log_path[-4:] == \".log\":\n",
    "                filter_logs.append(log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earlier-organization",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "charged-communist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'missing_data': [0, 10, 15, 20, 25, 5], 'all_variants': [2451, 2451, 2451, 2451, 2451, 2451], 'singleton_variants': [2451, 2451, 2451, 2451, 2451, 2451], 'parsimony_variants': [0, 0, 0, 0, 0, 0], 'singleton_variants_filter': [2451, 2451, 2451, 2451, 2451, 2451], 'parsimony_variants_filter': [0, 0, 0, 0, 0, 0], 'all_variants_filter': [2451, 2451, 2451, 2451, 2451, 2451]}\n"
     ]
    }
   ],
   "source": [
    "# Initialize data dict\n",
    "data = {\n",
    "        \"missing_data\" : [],\n",
    "        \"all_variants\" : [],\n",
    "        \"singleton_variants\" : [],\n",
    "        \"parsimony_variants\" : [],\n",
    "        \"singleton_variants_filter\" : [],\n",
    "        \"parsimony_variants_filter\" : [],\n",
    "        \"all_variants_filter\" : [],\n",
    "       }\n",
    "\n",
    "all_variants_term = \"Alignment length: \"\n",
    "singleton_variants_term = \"Total singleton sites: \"\n",
    "parsimony_variants_term = \"Parsimony informative sites: \"\n",
    "singleton_variants_filter_term = \"Singleton sites passing missing data filter:\"\n",
    "parsimony_variants_filter_term = \"Parsimony informative sites passing missing data filter:\"\n",
    "all_variants_filter_term = \"Total sites passing missing data filter:\"\n",
    "\n",
    "for log in filter_logs:\n",
    "    all_variants = 0\n",
    "    singleton_variants = 0\n",
    "    parsimony_variants = 0\n",
    "    threshold = int(os.path.basename(os.path.dirname(log)).replace(\"filter\", \"\"))\n",
    "        \n",
    "    with open(log, \"r\") as logfile:\n",
    "        for line in logfile:\n",
    "            # Get all sites count\n",
    "            if all_variants_term in line:\n",
    "                all_variants = int(line.split(all_variants_term)[1])\n",
    "            # Get singletons count\n",
    "            if singleton_variants_term in line:\n",
    "                singleton_variants = line.split(singleton_variants_term)[1]\n",
    "                singleton_variants = int(singleton_variants.split(\" \")[0])\n",
    "            # Get parsimony count\n",
    "            if parsimony_variants_term in line:\n",
    "                parsimony_variants = line.split(parsimony_variants_term)[1]\n",
    "                parsimony_variants = int(parsimony_variants.split(\" \")[0])\n",
    "            # Get filtered singletons count\n",
    "            if singleton_variants_filter_term in line:\n",
    "                singleton_variants_filter = int(line.split(singleton_variants_filter_term)[1])\n",
    "            # Get filtered parsimony count\n",
    "            if parsimony_variants_filter_term in line:\n",
    "                parsimony_variants_filter = int(line.split(parsimony_variants_filter_term)[1])                \n",
    "            # Get all filtered count\n",
    "            if all_variants_filter_term in line:\n",
    "                all_variants_filter = int(line.split(all_variants_filter_term)[1])     \n",
    "                \n",
    "                \n",
    "    data[\"missing_data\"].append(threshold)\n",
    "    data[\"all_variants\"].append(all_variants)\n",
    "    data[\"singleton_variants\"].append(singleton_variants)\n",
    "    data[\"parsimony_variants\"].append(parsimony_variants)\n",
    "    data[\"singleton_variants_filter\"].append(singleton_variants_filter)\n",
    "    data[\"parsimony_variants_filter\"].append(parsimony_variants_filter)\n",
    "    data[\"all_variants_filter\"].append(all_variants_filter)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-bankruptcy",
   "metadata": {},
   "source": [
    "## Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-agreement",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# ----------------------------------------\n",
    "# All Variants (lines)\n",
    "fig.add_trace(\n",
    "  go.Scatter(x = data[\"missing_data\"], y = data[\"all_variants\"], mode='lines', name = \"Total Variants\", line=dict(width=5))\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "  go.Scatter(x = data[\"missing_data\"], y = data[\"singleton_variants\"],mode='lines', name = \"Total Singletons\",line=dict(width=5))\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "  go.Scatter(x= data[\"missing_data\"], y = data[\"parsimony_variants\"], mode='lines', name = \"Total Parsimony Informative\", line=dict(width=5))\n",
    ")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Filtered Variants (bars)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x= data[\"missing_data\"],y = data[\"singleton_variants_filter\"],  name = \"Filtered Singletons\",),     \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x= data[\"missing_data\"],y = data[\"parsimony_variants_filter\"],  name = \"Filtered Parsimony Informative\",),     \n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Bar(x= data[\"missing_data\"],y = data[\"all_variants_filter\"],  name = \"Filtered All\",       \n",
    "    ),     \n",
    ")\n",
    "\n",
    "# ----------------------------------------\n",
    "# Customize Appearance\n",
    "fig.update_layout(\n",
    "  template=\"simple_white\", \n",
    "  width=720,\n",
    "  height=480,\n",
    "  title=(\"<b>Variants Across Missing Data Site Thresholds</b>\"),\n",
    "  title_x = 0.5,\n",
    "  xaxis = dict(\n",
    "      title = \"Missing Data Threshold Per Site (%)\",\n",
    "      tickvals = data[\"missing_data\"],\n",
    "      ),\n",
    "  yaxis_title = \"Number of Variant Sites\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    output_plot = snakemake.output.plot\n",
    "except NameError:\n",
    "    output_plot = os.path.join(output_dir, \"snippy-multi.snps.missing-data.html\")\n",
    "fig.write_html(output_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contained-cleaner",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
