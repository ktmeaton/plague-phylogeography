{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hollywood-malpractice",
   "metadata": {},
   "source": [
    "# Objectives\n",
    "\n",
    "1. Run clock analysis.\n",
    "1. Add clock stats to dataframe.\n",
    "1. Plot root-to-tip regression with date (tips+internals)\n",
    "1. Plot timetree.\n",
    "1. Plot subtrees.\n",
    "1. Plot map.\n",
    "\n",
    "**TO-DO**:\n",
    "\n",
    "1. Refine timetree parameters, specifically:\n",
    "    - Relaxed clock\n",
    "    - Marginal date estimation and confidence\n",
    "1. Visualize rates on timetree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-general",
   "metadata": {},
   "source": [
    "---\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-horizontal",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabulous-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import treetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, lines, gridspec, colors\n",
    "from matplotlib.path import Path\n",
    "from Bio import Phylo, AlignIO\n",
    "import os\n",
    "import io\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "import scipy\n",
    "#import augur\n",
    "import plotly\n",
    "\n",
    "import shapely.geometry\n",
    "import geopandas\n",
    "import augur\n",
    "\n",
    "# Install these\n",
    "import bezier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-opinion",
   "metadata": {},
   "source": [
    "## Input file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "perfect-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_path = \"../../docs/results/latest/parse_tree/parse_tree.nwk\"\n",
    "tree_df_path = \"../../docs/results/latest/mugration/mugration.tsv\"\n",
    "aln_path = \"../../docs/results/latest/snippy_multi/snippy-core_chromosome.snps.filter5.aln\"\n",
    "constant_sites_path = \"../../docs/results/latest/snippy_multi/snippy-core_chromosome.full.constant_sites.txt\"\n",
    "outdir = \"../../docs/results/latest/timetree/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-requirement",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "greek-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "\n",
    "NAME_COL = \"Name\"\n",
    "SCRIPT_NAME = \"timetree\"\n",
    "\n",
    "# Random\n",
    "random.seed(1152342, 2)\n",
    "np.random.seed(70262122)\n",
    "st0 = np.random.get_state()\n",
    "\n",
    "\n",
    "plt.rc('lines', linewidth=2)\n",
    "plt.rc('legend', labelspacing=0.75)\n",
    "plt.rc('legend', frameon=False) # legend frame\n",
    "\n",
    "# Mugration\n",
    "MUG_ATTR = \"Branch_Major\"\n",
    "GEO_ATTR = \"Province\"\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 10, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-korea",
   "metadata": {},
   "source": [
    "## Add constant sites to the snp alignment\n",
    "MEMORY PERMMITING!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "distributed-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "align = AlignIO.read(aln_path, format=\"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ahead-ecology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'constant_sites_dict = {\"A\": 0, \"C\" : 0, \"G\" : 0, \"T\" : 0}\\n\\nwith open(constant_sites_path, \"r\") as infile:\\n    constant_sites_list = infile.read().strip().split(\",\")\\n    constant_sites_dict[\"A\"] = int(constant_sites_list[0])\\n    constant_sites_dict[\"C\"] = int(constant_sites_list[1])\\n    constant_sites_dict[\"G\"] = int(constant_sites_list[2])\\n    constant_sites_dict[\"T\"] = int(constant_sites_list[3])    \\n\\nprint(constant_sites_dict)\\ntotal_constant_sites = sum(constant_sites_dict.values())\\nprint(\"Constant Sites:\", total_constant_sites)\\n\\n# Add the constant sites to each sample\\n# Iterate through each samples sequence\\nfor rec in align:\\n    # Iterate through each nucleotide for constant sites\\n    for nucleotide,count in constant_sites_dict.items():\\n        rec.seq = rec.seq + (nucleotide * count)   '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"constant_sites_dict = {\"A\": 0, \"C\" : 0, \"G\" : 0, \"T\" : 0}\n",
    "\n",
    "with open(constant_sites_path, \"r\") as infile:\n",
    "    constant_sites_list = infile.read().strip().split(\",\")\n",
    "    constant_sites_dict[\"A\"] = int(constant_sites_list[0])\n",
    "    constant_sites_dict[\"C\"] = int(constant_sites_list[1])\n",
    "    constant_sites_dict[\"G\"] = int(constant_sites_list[2])\n",
    "    constant_sites_dict[\"T\"] = int(constant_sites_list[3])    \n",
    "\n",
    "print(constant_sites_dict)\n",
    "total_constant_sites = sum(constant_sites_dict.values())\n",
    "print(\"Constant Sites:\", total_constant_sites)\n",
    "\n",
    "# Add the constant sites to each sample\n",
    "# Iterate through each samples sequence\n",
    "for rec in align:\n",
    "    # Iterate through each nucleotide for constant sites\n",
    "    for nucleotide,count in constant_sites_dict.items():\n",
    "        rec.seq = rec.seq + (nucleotide * count)   \"\"\"   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-preview",
   "metadata": {},
   "source": [
    "## Import divergence tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "diagnostic-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_div = Phylo.read(tree_path, \"newick\")\n",
    "tree_div.ladderize(reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-legislation",
   "metadata": {},
   "source": [
    "### Intialize TimeTree Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-gabriel",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to parse dates...\n",
      "\tUsing column 'Name' as name. This needs match the taxon names in the tree!!\n",
      "\tUsing column 'Date' as date.\n",
      "\n",
      "0.00\t-TreeAnc: set-up\n",
      "\n",
      "0.04\t-###TEST.TreeAnc.prepare_tree: BEGIN\n",
      "\n",
      "1.10\t-SequenceData: loaded alignment.\n",
      "1.10\t--SequenceData.aln: specified sequence length doesn't match alignment\n",
      "    \t  length. Treating difference as constant sites.\n",
      "\n",
      "1.10\t-SeqData: making compressed alignment...\n"
     ]
    }
   ],
   "source": [
    "# Use the utils function to parse the metadata dates\n",
    "dates_raw = treetime.utils.parse_dates(tree_df_path, \n",
    "                                   date_col=DATE_COL, \n",
    "                                   name_col = NAME_COL)\n",
    "\n",
    "# Remove nan elements (internal nodes)\n",
    "dates = {}\n",
    "for k,v in dates_raw.items():\n",
    "    if type(v) == list:\n",
    "        dates[k] = v\n",
    "    elif not pd.isnull(v):\n",
    "        dates[k] = v\n",
    "\n",
    "# Add the reference date\n",
    "dates[\"Reference\"] = REF_DATE\n",
    "\n",
    "# Construct the treetime object\n",
    "# Remember, including the alignment is crucial!\n",
    "tt = treetime.TreeTime(dates=dates, \n",
    "                       aln=align,                     \n",
    "                       tree=tree_path, \n",
    "                       verbose=4, \n",
    "                       fill_overhangs=False,\n",
    "                       seq_len=REF_LEN,                        \n",
    "                      )\n",
    "\n",
    "# Remove outliers\n",
    "tt.clock_filter(reroot=None, \n",
    "                n_iqd=N_IQD, \n",
    "                plot=False,\n",
    "               )\n",
    "\n",
    "# Check rtt\n",
    "print(tt.date2dist.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-ridge",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Clock Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-audience",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize stdout capture\n",
    "old_stdout = sys.stdout\n",
    "new_stdout = io.StringIO()\n",
    "sys.stdout = new_stdout\n",
    "\n",
    "# PARAM MIN: root='-4101-09-02'\n",
    "#tt.run()\n",
    "\n",
    "# PARAM STABLE='-4030-01-03'\n",
    "# My suspicion is that the branch length mode is the key variable\n",
    "\"\"\"\n",
    "tt.run(resolve_polytomies=False, \n",
    "       Tc=\"skyline\", \n",
    "       max_iter=3,\n",
    "       relaxed_clock={\"slack\":1.0, \"coupling\": 0},\n",
    "       infer_gtr=True,\n",
    "       )\n",
    "\"\"\"\n",
    "\n",
    "# PARAM TEST='-4083-05-20'\n",
    "# My suspicion is that the branch length mode is the key variable\n",
    "tt.run(resolve_polytomies=False, \n",
    "       Tc=\"skyline\", \n",
    "       max_iter=MAX_ITER,\n",
    "       relaxed_clock={\"slack\":5.0, \"coupling\": 0},\n",
    "       infer_gtr=True,\n",
    "       time_marginal=TIME_MARGINAL,\n",
    "       sequence_margial=SEQ_MARGINAL,\n",
    "       )\n",
    "# PARAM SET X date='-19904-12-03'\n",
    "\"\"\"\n",
    "tt.run(branch_length_mode = \"input\",\n",
    "               n_iqd=3,\n",
    "               root=None,\n",
    "               infer_gtr=True,\n",
    "               resolve_polytomies=False,\n",
    "               relaxed_clock={\"slack\":1.0, \"coupling\": 0},\n",
    "               max_iter=3,\n",
    "               Tc=\"skyline\",\n",
    "               use_covariation=False,\n",
    "               vary_rate=False,\n",
    "               time_marginal=\"assign\",\n",
    "               sequence_marginal=True,\n",
    "               verbose=4,\n",
    "              )\n",
    "\"\"\"\n",
    "\n",
    "# Save stdout to file\n",
    "output = new_stdout.getvalue()\n",
    "out_path = os.path.join(outdir, SCRIPT_NAME + \".log\") \n",
    "with open(out_path, \"w\") as file:\n",
    "    file.write(output)\n",
    "# Restore stdout\n",
    "sys.stdout = old_stdout\n",
    "print(\"Standard output restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check\n",
    "tt.tree.common_ancestor(\"NODE0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-anthropology",
   "metadata": {},
   "source": [
    "### Ladderize tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.tree.ladderize(reverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "processed-playing",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Add clock stats to data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-greek",
   "metadata": {},
   "source": [
    "## 'Default' stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-crossing",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path_gtr = os.path.join(outdir, SCRIPT_NAME + \"_gtr.txt\" )\n",
    "with open(out_path_gtr, 'w', encoding='utf-8') as outfile:\n",
    "    outfile.write(str(tt.gtr)+'\\n')\n",
    "\n",
    "# ----------------------------\n",
    "# Marginal Confidence\n",
    "if TIME_MARGINAL:\n",
    "    out_path_dates = os.path.join(outdir, SCRIPT_NAME + \"_dates.tsv\")\n",
    "\n",
    "    with open(out_path_dates, \"w\") as outfile:\n",
    "        outfile.write('#Lower and upper bound delineate the {0:.0f}% max posterior region\\n'.format(CONFIDENCE*100))\n",
    "        outfile.write('#node\\tdate\\tnumeric date\\tlower bound\\tupper bound\\n')\n",
    "\n",
    "        for c in tt.tree.find_clades():\n",
    "            if c.bad_branch:\n",
    "                # Should these be NO DATA CHAR instead?\n",
    "                outfile.write(c.name + \"\\t\" + NO_DATA_CHAR + \n",
    "                              \"\\t\" + NO_DATA_CHAR + \n",
    "                              \"\\t\" + NO_DATA_CHAR + \n",
    "                              \"\\t\" + NO_DATA_CHAR + \"\\n\")\n",
    "                outfile.write('%s\\t--\\t--\\t--\\t--\\n'%(c.name))\n",
    "            else:\n",
    "                conf = tt.get_max_posterior_region(c, fraction=CONFIDENCE) \n",
    "                outfile.write('%s\\t%s\\t%f\\t%f\\t%f\\n'%(c.name, c.date, c.numdate,conf[0], conf[1]))\n",
    "                \n",
    "# ----------------------------\n",
    "# Rate Variation\n",
    "if RELAXED_CLOCK:\n",
    "    min_gamma = ['', 1]\n",
    "    max_gamma = ['', 1]\n",
    "    gamma_dict = {}\n",
    "\n",
    "    out_path_rates = os.path.join(outdir, SCRIPT_NAME + \"_rates.tsv\")\n",
    "    with open(out_path_rates, \"w\") as outfile:\n",
    "        outfile.write(\"#node\\tclock_length\\tmutation_length\\trate\\tfold_change\\n\")\n",
    "\n",
    "        for c in tt.tree.find_clades(order=\"preorder\"):\n",
    "            if c==tt.tree.root:\n",
    "                continue\n",
    "            g = c.branch_length_interpolator.gamma\n",
    "            if g <= min_gamma[1]:\n",
    "                min_gamma[0] = c.name\n",
    "                min_gamma[1] = g\n",
    "            if g >= max_gamma[1]:\n",
    "                max_gamma[0] = c.name\n",
    "                max_gamma[1] = g\n",
    "            outfile.write(\"%s\\t%1.3e\\t%1.3e\\t%1.3e\\t%1.2f\\n\"%(c.name, c.clock_length, c.mutation_length, tt.date2dist.clock_rate*g, g))\n",
    "            gamma_dict[c.name] = g\n",
    "\n",
    "    print(\"min_gamma: \", min_gamma)\n",
    "    print(\"max_gamma: \", max_gamma)\n",
    "    print(\"gamma ratio: \", max_gamma[1] / min_gamma[1])     \n",
    "    \n",
    "    # PLOT\n",
    "    fig, ax1 = plt.subplots(1, dpi=dpi, figsize=figsize_mini)\n",
    "\n",
    "    sns.histplot(x = list(gamma_dict.values()), \n",
    "             ax=ax1,\n",
    "             alpha=0.75,\n",
    "             ) \n",
    "    \n",
    "    ax1.set_xlabel(\"Rate Multiplier\")\n",
    "    ax1.set_ylabel(\"Number of Branches\")\n",
    "    #ax1.set_xlim(0,max_gamma[1])\n",
    "    ax1.set_title(\"Rate Variation Across Branches\")\n",
    "    \n",
    "    # Save\n",
    "    out_path = os.path.join(outdir, SCRIPT_NAME + \"_rate_variation.\" + FMT) \n",
    "    plt.savefig(out_path, \n",
    "            dpi=dpi, \n",
    "            bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vital-simulation",
   "metadata": {},
   "source": [
    "## Add stats to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_df = pd.read_csv(tree_df_path, sep='\\t')\n",
    "# Fix the problem with multiple forms of NA in the table\n",
    "# Consolidate missing data to the NO_DATA_CHAR\n",
    "tree_df.fillna(NO_DATA_CHAR, inplace=True)\n",
    "tree_df.set_index(NAME_COL, inplace=True)\n",
    "\n",
    "# make a copy of the tree\n",
    "tt_copy = copy.deepcopy(tt)\n",
    "tt_copy.branch_length_to_years()\n",
    "\n",
    "x_posns = get_x_positions(tt_copy.tree)\n",
    "y_posns = get_y_positions(tt_copy.tree)\n",
    "tt_reg = tt_copy.setup_TreeRegression()\n",
    "\n",
    "# Create new columns\n",
    "tree_df[\"timetree_\" + DATE_COL] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_coord_x\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_coord_y\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))] \n",
    "tree_df[\"timetree_reg_x\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_reg_y\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_reg_bad\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "tree_df[\"timetree_\" + DATE_COL + \"_Confidence\"] = [NO_DATA_CHAR for row in range(0,len(tree_df))]  \n",
    "\n",
    "# Add x and y coordinates\n",
    "for c in tt_copy.tree.find_clades():       \n",
    "    # Add dates and confidence\n",
    "    tree_df.at[c.name, \"timetree_\" + DATE_COL] = c.numdate\n",
    "    conf = tt_copy.get_max_posterior_region(c, fraction=CONFIDENCE)\n",
    "    conf = [float(conf[0]), float(conf[1])]\n",
    "    tree_df.at[c.name, \"timetree_\" + DATE_COL + \"_Confidence\"] = conf\n",
    "    \n",
    "    # Scatter coordinates\n",
    "    coord_x = [value for key,value in x_posns.items() if key.name == c.name][0]\n",
    "    coord_y = [value for key,value in y_posns.items() if key.name == c.name][0]\n",
    "    tree_df.at[c.name, 'timetree_coord_x'] = coord_x\n",
    "    tree_df.at[c.name, 'timetree_coord_y'] = coord_y\n",
    "    \n",
    "    # Regression\n",
    "    reg_y = c._v\n",
    "    if c.is_terminal():\n",
    "        reg_x = tt_reg.tip_value(c)\n",
    "    else:\n",
    "        reg_x = c.numdate\n",
    "    reg_bad = c.bad_branch  if hasattr(c, 'bad_branch') else False\n",
    "    tree_df.at[c.name, 'timetree_reg_x'] = reg_x\n",
    "    tree_df.at[c.name, 'timetree_reg_y'] = reg_y    \n",
    "    tree_df.at[c.name, 'timetree_reg_bad'] = reg_bad\n",
    "\n",
    "# Fix up new values that could be none\n",
    "tree_df.fillna(NO_DATA_CHAR, inplace=True)\n",
    "tree_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-filter",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Plot root-to-tip regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-credits",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root to tip regression\n",
    "fig, (ax1) = plt.subplots(1, dpi=400, figsize=figsize_mini)\n",
    "\n",
    "\n",
    "tip_data = tree_df[(tree_df[\"timetree_reg_x\"] != NO_DATA_CHAR) &\n",
    "                   (tree_df[\"Branch_Support_Color\"] == TERM_COL) ]\n",
    "\n",
    "int_data = tree_df[(tree_df[\"timetree_reg_x\"] != NO_DATA_CHAR) & (tree_df[\"Branch_Support_Color\"] != TERM_COL)]\n",
    "\n",
    "regression = tt.clock_model\n",
    "t_mrca = -regression['intercept']/regression['slope']\n",
    "# This does not filter for bad branches!\n",
    "time_span = np.max(tip_data[\"timetree_reg_x\"]) - np.min(tip_data[\"timetree_reg_x\"])\n",
    "x_vals = np.array([max(np.min(tip_data[\"timetree_reg_x\"]), t_mrca) - 0.1*time_span, \n",
    "                   np.max(tip_data[\"timetree_reg_x\"]+0.05*time_span)])\n",
    "\n",
    "res = scipy.stats.linregress(list(tip_data[\"timetree_reg_x\"]),list(tip_data[\"timetree_reg_y\"]))\n",
    "\n",
    "# When no confidence is enabled\n",
    "dev_rtt = None\n",
    "dev_slope = None\n",
    "\n",
    "# Plot tips\n",
    "ax1.scatter(data=tip_data, \n",
    "            x=\"timetree_reg_x\", \n",
    "            y=\"timetree_reg_y\",\n",
    "            label=\"Tips\",\n",
    "            color=DISC_CMAPLIST[1],\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "            s=15,\n",
    "            alpha=0.75,\n",
    "            zorder=2,)\n",
    "\n",
    "# Plot internal nodes\n",
    "ax1.scatter(data=int_data, \n",
    "            x=\"timetree_reg_x\", \n",
    "            y=\"timetree_reg_y\",\n",
    "            label=\"Internal Nodes\",\n",
    "            color=DISC_CMAPLIST[2],\n",
    "            edgecolor=\"black\",\n",
    "            linewidth=0.5,\n",
    "            s=15,\n",
    "            alpha=0.75,\n",
    "            zorder=1,)\n",
    "\n",
    "# Regression line\n",
    "ax1.plot(x_vals, \n",
    "         regression['slope']*x_vals + regression['intercept'],\n",
    "         label = r\"$y=\\alpha + \\beta t$\"+\"\\n\"+\n",
    "                r\"$\\beta=$%1.2e\"%(regression[\"slope\"])\n",
    "                + (\"+/- %1.e\"%dev_slope if dev_slope else \"\") +\n",
    "                \"\\nRÂ²={:.3f}\".format(res.rvalue**2) +\n",
    "                \"\\nRoot Date: %1.1f\"%(-regression['intercept']/regression['slope']) +\n",
    "                (\"+/- %1.2f\"%dev_rtt if dev_rtt else \"\"),\n",
    "         color=DISC_CMAPLIST[0],\n",
    "        )\n",
    "\n",
    "# Labels\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Root-to-Tip Distance\")\n",
    "ax1.set_title(\"Root-to-Tip Regression on Date\")\n",
    "# Legend\n",
    "plt.legend(loc=2)\n",
    "\n",
    "# Save\n",
    "out_path = os.path.join(outdir, SCRIPT_NAME + \"_rtt.\" + FMT) \n",
    "plt.savefig(out_path, \n",
    "            dpi=dpi, \n",
    "            bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-manual",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Plot timetreee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-brisbane",
   "metadata": {},
   "source": [
    "## Important events to label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_copy = copy.deepcopy(tt)\n",
    "\n",
    "# Clade based events\n",
    "first_pandemic_tips = list(tree_df[(tree_df[\"Branch_Major\"] == \"First Pandemic\")].index)\n",
    "first_pandemic_mrca = tt_copy.tree.common_ancestor(first_pandemic_tips)\n",
    "\n",
    "second_pandemic_tips = list(tree_df[(tree_df[\"Branch_Major\"] == \"Second Pandemic\")].index)\n",
    "second_pandemic_mrca = tt_copy.tree.common_ancestor(second_pandemic_tips)\n",
    "\n",
    "third_pandemic_tips = list(tree_df[(tree_df[\"Branch_Major\"] == \"1.ORI\")].index)\n",
    "third_pandemic_mrca = tt_copy.tree.common_ancestor(third_pandemic_tips)\n",
    "\n",
    "two_med_tips = list(tree_df[(tree_df[\"Branch_Major\"] == \"2.MED\")].index)\n",
    "two_med_mrca = tt_copy.tree.common_ancestor(two_med_tips)\n",
    "\n",
    "target_attr = {\"2.ANT\": '', \"2.MED\": '', \"3.ANT\": \"\", \"4.ANT\": \"\"}\n",
    "for c in tt_copy.tree.get_terminals():\n",
    "    mug_val = tree_df[MUG_ATTR][c.name]\n",
    "    if mug_val in target_attr and not target_attr[mug_val]:\n",
    "        target_attr[mug_val] = c\n",
    "\n",
    "big_bang_node = tt_copy.tree.common_ancestor(list(target_attr.values()))\n",
    "\n",
    "# Sample based events\n",
    "black_death_node = tt_copy.tree.common_ancestor(\"SAMN00715800\") # black death node: 8291\n",
    "justinian_plague_node = tt_copy.tree.common_ancestor(\"SAMEA4354665\") #justinian plague node: AE1175 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "treated-blame",
   "metadata": {},
   "source": [
    "## Plot div tree vs time tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-recording",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, \n",
    "                         dpi=dpi, \n",
    "                         gridspec_kw={'wspace': 0.05}, \n",
    "                         figsize=figsize_alt,\n",
    "                         sharey=True,\n",
    "                         )\n",
    "\n",
    "plt.rc('lines', linewidth=0.5)\n",
    "\n",
    "# Create a dictionary to hold mapping of attribute : color\n",
    "# Will need this later for legend construction?\n",
    "mug_dict = {MUG_ATTR: {\"hex_color\": {}}}\n",
    "\n",
    "# Make copies for modification\n",
    "tree_div_copy = copy.deepcopy(tree_div)\n",
    "tt_copy = copy.deepcopy(tt)\n",
    "tt_copy.branch_length_to_years()\n",
    "\n",
    "for c in tree_div_copy.find_clades():\n",
    "    c.color = \"black\"\n",
    "# --------------------------------------------\n",
    "# Draw trees\n",
    "for t,ax in zip([tree_div_copy, tt_copy.tree], [ax1, ax2]):\n",
    "    # Color the tree by an attribute\n",
    "    hex_dict = color_tree(tree=t, \n",
    "                          df=tree_df, \n",
    "                          attribute=\"Mugration_\" + MUG_ATTR,\n",
    "                          attribute_confidence=\"Mugration_\" + MUG_ATTR + \"_Confidence\",\n",
    "                          threshold_confidence=MUG_CONF_THRESH,                          \n",
    "                          color_pal=CONT_COLOR_PAL)\n",
    "    # Add the Low confidence Element\n",
    "    hex_dict[\"Low Confidence\"] = \"grey\"\n",
    "    mug_dict[MUG_ATTR][\"hex_color\"] = hex_dict\n",
    "    Phylo.draw(t, \n",
    "           axes=ax, \n",
    "           show_confidence=False, \n",
    "           label_func = lambda x:'', \n",
    "           do_show=False)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Draw tips\n",
    "tip_div_data = tree_df[(tree_df[\"Branch_Support_Color\"] == TERM_COL)]\n",
    "tip_time_data = tree_df[(tree_df[\"Branch_Support_Color\"] == TERM_COL) & (tree_df[\"timetree_coord_x\"] != NO_DATA_CHAR)]\n",
    "\n",
    "for df,ax,prefix in zip([tip_div_data, tip_time_data], [ax1, ax2], [\"coord_\", \"timetree_coord_\"]):\n",
    "    tip_colors = []\n",
    "    for attr in df[\"Mugration_\" + MUG_ATTR]:\n",
    "        tip_colors.append(hex_dict[attr])\n",
    "    ax.scatter(data=df,\n",
    "               x=prefix + \"x\", \n",
    "               y=prefix + \"y\",\n",
    "               s=0.5, \n",
    "               c=tip_colors,\n",
    "               label=\"\",)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Draw events\n",
    "event_marker_size = 50\n",
    "event_dict = {\n",
    "    \"First Pandemic\": {\n",
    "        \"node\": justinian_plague_node,\n",
    "        \"marker\": \"P\",\n",
    "        \"color\": mug_dict[MUG_ATTR][\"hex_color\"][\"First Pandemic\"],\n",
    "    }, \n",
    "    \"Big Bang\": {\n",
    "        \"node\": big_bang_node,\n",
    "        \"marker\": \"D\",\n",
    "        \"color\": mug_dict[MUG_ATTR][\"hex_color\"][\"Low Confidence\"],\n",
    "    },\n",
    "    \"Black Death\" : {\n",
    "        \"node\": black_death_node,\n",
    "        \"marker\": \"*\",\n",
    "        \"color\": mug_dict[MUG_ATTR][\"hex_color\"][\"Second Pandemic\"],\n",
    "    },\n",
    "    \"20th Century Plague\": {\n",
    "        \"node\" : third_pandemic_mrca,\n",
    "        \"marker\" : \"X\",\n",
    "        \"color\": mug_dict[MUG_ATTR][\"hex_color\"][\"1.ORI\"],\n",
    "    }}\n",
    "\n",
    "for event in event_dict:\n",
    "    # shift markers up\n",
    "    y_shift = 5\n",
    "    # plot on both axes\n",
    "    ax1.scatter(\n",
    "        x = tree_df[\"coord_x\"][event_dict[event][\"node\"].name], \n",
    "        y = tree_df[\"coord_y\"][event_dict[event][\"node\"].name] + y_shift,\n",
    "        marker=event_dict[event][\"marker\"], \n",
    "        label=event, \n",
    "        color=event_dict[event][\"color\"], \n",
    "        ec=\"black\",\n",
    "        s=event_marker_size,\n",
    "        zorder=3,\n",
    "        )    \n",
    "    ax2.scatter(\n",
    "        x = tree_df[\"timetree_coord_x\"][event_dict[event][\"node\"].name], \n",
    "        y = tree_df[\"timetree_coord_y\"][event_dict[event][\"node\"].name] + y_shift,\n",
    "        marker=event_dict[event][\"marker\"], \n",
    "        label=event, \n",
    "        color=event_dict[event][\"color\"], \n",
    "        ec=\"black\",\n",
    "        s=event_marker_size,\n",
    "        zorder=3,\n",
    "        )\n",
    "\n",
    "# --------------------------------------------\n",
    "# Ticks\n",
    "\n",
    "# The y axis is not particularly meaning, remove the ticks\n",
    "ax1.set_yticks([])\n",
    "ax2.set_yticks([])\n",
    "\n",
    "ticks_dict = convert_timetree_ticks(tree=tt_copy.tree, step=500)\n",
    "\n",
    "# Set the new tick locations and labels\n",
    "ax2.set_xticks(ticks_dict[\"tick_locs\"])\n",
    "ax2.set_xticklabels(ticks_dict[\"tick_labels\"])\n",
    "\n",
    "date_to_x = (float(ticks_dict[\"tick_locs\"][-1]) - float(ticks_dict[\"tick_labels\"][-1]))\n",
    "\n",
    "# --------------------------------------------\n",
    "# Confidence\n",
    "\"\"\"\n",
    "for rec in tree_df.iterrows():\n",
    "    node_name = rec[0]\n",
    "    date_conf = tree_df[\"timetree_\" + DATE_COL + \"_Confidence\"][node_name]\n",
    "    if date_conf != NO_DATA_CHAR:\n",
    "        date_convert = [date_conf[0] + date_to_x, date_conf[1] + date_to_x ]\n",
    "        date_y = tree_df[\"timetree_coord_y\"][node_name]\n",
    "        ax2.plot([date_convert[0], date_convert[1]], \n",
    "                 [date_y,date_y],\n",
    "                 linewidth=1,\n",
    "                 alpha=0.5,\n",
    "                 color=\"grey\",\n",
    "                )\n",
    "\"\"\"\n",
    "# --------------------------------------------\n",
    "# Labels\n",
    "\n",
    "ax1.set_xlabel('Branch Length')\n",
    "ax1.set_ylabel('')    \n",
    "\n",
    "ax2.set_xlabel('Year')\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "ax1.set_title(\"Divergence Tree\")\n",
    "ax2.set_title(\"Time Tree\")\n",
    "\n",
    "\n",
    "# --------------------------------------------\n",
    "# Lines\n",
    "\n",
    "# Vertical lines for dates\n",
    "for loc in ticks_dict[\"tick_locs\"]:\n",
    "    ax2.axvline(x=loc, color=\"darkgrey\", alpha=0.5)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Limits\n",
    "\n",
    "x_buffer = max(tree_df[\"coord_x\"]) * 0.05\n",
    "y_buffer = math.ceil(len(tree_div_copy.get_terminals()) * 0.01)\n",
    "\n",
    "ax1.set_xlim(0 - x_buffer, max(tree_df[\"coord_x\"]) + x_buffer)\n",
    "ax1.set_ylim(len(tree_div_copy.get_terminals()) + y_buffer, 0 - y_buffer)\n",
    "\n",
    "x_buffer = math.ceil((ticks_dict[\"tick_locs\"][-1] - ticks_dict[\"tick_locs\"][0]) * 0.05)\n",
    "y_buffer = math.ceil(len(tt_copy.tree.get_terminals()) * 0.05)\n",
    "\n",
    "# No x buffer on lower end\n",
    "ax2.set_xlim(ticks_dict[\"tick_locs\"][0], ticks_dict[\"tick_locs\"][-1] + x_buffer)\n",
    "ax2.set_ylim(len(tt_copy.tree.get_terminals()) + y_buffer, 0 - y_buffer)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Legends\n",
    "\n",
    "# Make a custom patches legend for the mugration attribute\n",
    "legend_mug_elements = [patches.Patch(facecolor=value, edgecolor=value,) for value in mug_dict[MUG_ATTR][\"hex_color\"].values()]\n",
    "legend_mug_labels = list(mug_dict[MUG_ATTR][\"hex_color\"].keys())\n",
    "\n",
    "legend_mug = ax2.legend(legend_mug_elements, \n",
    "           legend_mug_labels, \n",
    "           bbox_to_anchor=(1.0, 1.0), \n",
    "           loc='upper left', \n",
    "           title=\"Major Branches\",)\n",
    "\n",
    "legend_events = ax2.legend(bbox_to_anchor=(1.0, 0.00), \n",
    "           loc='lower left',\n",
    "           title=\"Events\",\n",
    "           labelspacing=2,)\n",
    "\n",
    "# Add multiple legends as artists\n",
    "ax2.add_artist(legend_mug)\n",
    "ax2.add_artist(legend_events)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Save\n",
    "out_path = os.path.join(outdir, SCRIPT_NAME + \"_divtree_{}.{}\".format(MUG_ATTR.lower(), FMT))\n",
    "plt.savefig(out_path, dpi=dpi, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-indianapolis",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Plot Subtrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "median-standard",
   "metadata": {},
   "source": [
    "## Setup Subtree Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-exclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "subtree_dict = {\n",
    "    \"Second Pandemic\" : {\n",
    "        \"tips\": [\"SAMN00715800\",\"SAMEA3713715\", \"SAMEA5818822\"], # 8291, OBS137, STN008\n",
    "        \"color\": mug_dict[MUG_ATTR][\"hex_color\"][\"Second Pandemic\"],\n",
    "        \"node\" : second_pandemic_mrca,\n",
    "        \"collapse\": [\n",
    "            {\"2.MED\": [], \"2.ANT\": []},\n",
    "            {\"3.ANT\": [], \"4.ANT\": []},\n",
    "            {\"1.ANT\": [], \"1.ORI\": []},            \n",
    "        ],\n",
    "        \"step\" : 50,     \n",
    "    },\n",
    "    \"First Pandemic\" : {\n",
    "        \"tips\": [\"SAMEA4354665\", \"SAMEA1061800\"], # AE1175, DA101\n",
    "        \"color\": mug_dict[MUG_ATTR][\"hex_color\"][\"First Pandemic\"],\n",
    "        \"node\" : first_pandemic_mrca,\n",
    "        \"collapse\": [\n",
    "            {\"1.ORI\": [], \"0.ANT\": []},\n",
    "        ],\n",
    "        \"step\" : 100,        \n",
    "    },  \n",
    "    \"1.ORI\" : {\n",
    "        \"tips\": [\"Reference\"],\n",
    "        \"color\": mug_dict[MUG_ATTR][\"hex_color\"][\"1.ORI\"],\n",
    "        \"node\" : third_pandemic_mrca,\n",
    "        \"collapse\": [\n",
    "            {\"1.IN\": [],},\n",
    "        ],\n",
    "        \"step\" : 25,       \n",
    "    },   \n",
    "    \"2.MED\" : {\n",
    "        \"tips\": two_med_tips,\n",
    "        \"node\" : two_med_mrca,\n",
    "        \"collapse\": [\n",
    "            {\"2.ANT\": [],},\n",
    "        ],\n",
    "        \"step\" : 100,          \n",
    "    },      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-brown",
   "metadata": {},
   "source": [
    "## Add subtree data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No copying is preferred here, we use the trees modified from the previous plotting step\n",
    "# Select nodes will be copied so the original tree is not collapsed\n",
    "\n",
    "#for event_label in [list(subtree_dict.keys())[0]]:\n",
    "for event_label in subtree_dict:\n",
    "    # If a node was not provided, search for the mrca of the provided tips\n",
    "    if not subtree_dict[event_label][\"node\"]:\n",
    "        subtree_dict[event_label][\"node\"] = tt_copy.tree.common_ancestor(subtree_dict[event_label][\"tips\"])\n",
    "    \n",
    "    t = tt_copy.tree.common_ancestor(subtree_dict[event_label][\"node\"].name)\n",
    "    # set t to the parent\n",
    "    t = tt_copy.tree.get_path(t.name)[-2]\n",
    "    \n",
    "    # make a copy so we don't modify the original node directly\n",
    "    t = copy.deepcopy(t)\n",
    "               \n",
    "    # --------------------------------------------\n",
    "    # Collapse Undesired Clades\n",
    "    if len(subtree_dict[event_label][\"collapse\"]) > 0:   \n",
    "        # If just one collapse clade finding mrca of all        \n",
    "        for collapse_clade in subtree_dict[event_label][\"collapse\"]:\n",
    "            # Find the tips that fullfills the value criteria\n",
    "            for c in t.get_terminals():\n",
    "                mug_val = tree_df[MUG_ATTR][c.name]\n",
    "                if mug_val in collapse_clade:\n",
    "                    collapse_clade[mug_val].append(c.name)\n",
    "\n",
    "            #target_nodes =  list(collapse_clade.values())\n",
    "            target_nodes = []\n",
    "            for node in collapse_clade.values():\n",
    "                target_nodes += node\n",
    "            if len(\"\".join(target_nodes)) > 0:\n",
    "                collapse_node = t.common_ancestor(target_nodes) \n",
    "                # Collapse all clades\n",
    "                for c in collapse_node.find_clades():\n",
    "                    t.collapse(target=c.name)\n",
    "    \n",
    "    # Replace original node in dictionary\n",
    "    subtree_dict[event_label][\"node\"] = t    \n",
    "    \n",
    "    # --------------------------------------------\n",
    "    # Geo - Points\n",
    "    \n",
    "    # Select nodes from dataset from this subtree\n",
    "    t_clades = [c.name for c in t.find_clades()]\n",
    "    # Temporary pandas dataframe\n",
    "    df = tree_df.loc[ t_clades , : ]\n",
    "    \n",
    "    # Convert to geopandas dataframe\n",
    "    geometry = [shapely.geometry.Point(xy) for xy in zip(df[\"Mugration_\" + GEO_ATTR + \"_Lon\"], df[\"Mugration_\" + GEO_ATTR + \"_Lat\"])]\n",
    "    gdf = geopandas.GeoDataFrame(df, crs=CRS, geometry=geometry)\n",
    "    \n",
    "    # Count up the locations for sizing points\n",
    "    gdf_counts = {}\n",
    "    for geo in gdf[\"Mugration_\" + GEO_ATTR]:\n",
    "        if geo not in gdf_counts:\n",
    "            gdf_counts[geo] = 0\n",
    "        gdf_counts[geo] += 1\n",
    "        \n",
    "    # Store it in the dictionary\n",
    "    subtree_dict[event_label][\"gdf\"] = gdf\n",
    "    subtree_dict[event_label][\"gdf_counts\"] = gdf_counts \n",
    "    \n",
    "    gdf_colors = []\n",
    "    for node in gdf.index:\n",
    "        gdf_colors.append(hex_dict[gdf[\"Mugration_\" + MUG_ATTR][node]])\n",
    "    subtree_dict[event_label][\"gdf_colors\"] = gdf_colors \n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Geo - Bezier\n",
    "    \n",
    "    gdf_bezier = {}\n",
    "    # Alter the bezier curve shape\n",
    "    control_factor = 0.95\n",
    "    # Iterate through the terminals\n",
    "    for term in t.get_terminals():\n",
    "\n",
    "        # Initialize locations to none for each curve\n",
    "        prev_loc = None\n",
    "        prev_name = None\n",
    "\n",
    "        # Force the root to be part of the path\n",
    "        term_path = [t.root] + t.get_path(term.name)\n",
    "        \n",
    "        # Iterate through the nodes in the path from terminal to root\n",
    "        for node in term_path:\n",
    "            # Store the current location\n",
    "            cur_loc = gdf[\"geometry\"][node.name]\n",
    "            cur_name = node.name\n",
    "            # Fetch the color based on a mugration attribute\n",
    "            line_color = hex_dict[gdf[\"Mugration_\" + MUG_ATTR][node.name]]\n",
    "\n",
    "            # If this is the root, mark it, fix up the location\n",
    "            if not prev_loc:\n",
    "                prev_loc = cur_loc\n",
    "                prev_name = cur_name\n",
    "\n",
    "            # If staying in place, don't store\n",
    "            if prev_loc == cur_loc:\n",
    "                continue\n",
    "\n",
    "            # Westward movements are depicted by lines with an upward curvature \n",
    "            control_x = prev_loc.x\n",
    "            if cur_loc.x < prev_loc.x:\n",
    "                control_y = max(cur_loc.y, prev_loc.y)            \n",
    "            # Eastward movements are depicted by lines with a downward curvature\n",
    "            else:\n",
    "                control_y = min(cur_loc.y, prev_loc.y)\n",
    "\n",
    "            # Curved lines\n",
    "            nodes = np.asfortranarray([[prev_loc.x, control_x, cur_loc.x], [prev_loc.y, control_y, cur_loc.y]])\n",
    "            curve = bezier.Curve(nodes, degree=2)\n",
    "            curve_conf = gdf[\"Mugration_\" + GEO_ATTR + \"_Confidence\"][node.name]\n",
    "            \n",
    "            # Check if this curve has already been added\n",
    "            if (prev_name, cur_name) not in gdf_bezier:\n",
    "                gdf_bezier[(prev_name, cur_name)] = {}\n",
    "                gdf_bezier[(prev_name, cur_name)][\"curve\"] = curve\n",
    "                gdf_bezier[(prev_name, cur_name)][\"conf\"] = curve_conf\n",
    "\n",
    "            prev_loc = cur_loc  \n",
    "            prev_name = cur_name\n",
    "    \n",
    "    subtree_dict[event_label][\"gdf_bezier\"] = gdf_bezier\n",
    "    \n",
    "    # --------------------------------------------                \n",
    "    # Exclude rows\n",
    "    if event_label == \"2.MED\":\n",
    "        exclude_sample = gdf[gdf[\"Country\"] == \"United States of America\"].index[0]\n",
    "        gdf.drop(index=exclude_sample, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threatened-opportunity",
   "metadata": {},
   "source": [
    "## Plot subtrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-contrary",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for event_label in subtree_dict:\n",
    "    # Get the subtree\n",
    "    t = subtree_dict[event_label][\"node\"]\n",
    "    \n",
    "    fig, ax1 = plt.subplots(1, dpi=dpi, figsize=figsize)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    # Draw Tree\n",
    "    # Scale line width depending on samples\n",
    "    plt.rc(\"font\", size=3)\n",
    "    if len(t.get_terminals()) < 50:\n",
    "        plt.rc('lines', linewidth=1)\n",
    "    else:\n",
    "        plt.rc('lines', linewidth=0.5)\n",
    "        fig.set_size_inches(figsize[0], figsize[1] * 2)\n",
    "    #label_func = lambda x: tree_df[\"Strain\"][x.name] if tree_df[\"Strain\"][x.name] != \"NA\" else \"\"\n",
    "    #label_func = lambda x: x\n",
    "    label_func = lambda x: (\n",
    "        \"   {} ({})\".format(tree_df[\"Country\"][x.name], tree_df[\"Strain\"][x.name]) \n",
    "                  if tree_df[\"Country\"][x.name] != \"NA\" \n",
    "                  else \"({})\".format(tree_df[\"Strain\"][x.name])\n",
    "                    if tree_df[\"Strain\"][x.name] != \"NA\"\n",
    "                  else \"\"\n",
    "    )\n",
    "    Phylo.draw(t,\n",
    "               axes=ax1, \n",
    "               show_confidence=False, \n",
    "               label_func = label_func, \n",
    "               do_show=False)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Labels\n",
    "    ax1.set_xlabel(\"Year\")\n",
    "    ax1.set_ylabel(\"\")  \n",
    "    ax1.set_title(event_label)\n",
    "    \n",
    "    # --------------------------------------------\n",
    "    # Ticks\n",
    "\n",
    "    # The y axis is not particularly meaning, remove the ticks\n",
    "    ax1.set_yticks([])\n",
    "\n",
    "    ticks_dict = convert_timetree_ticks(tree=t, step=subtree_dict[event_label][\"step\"])\n",
    "    ax1.set_xticklabels(ticks_dict[\"tick_labels\"])\n",
    "    ax1.set_xticks(ticks_dict[\"tick_locs\"])\n",
    "\n",
    "    date_to_x = float(ticks_dict[\"tick_labels\"][-1]) - float(ticks_dict[\"tick_locs\"][-1])\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Draw Tips\n",
    "\n",
    "    tip_x = [c.numdate - date_to_x for c in t.get_terminals()]\n",
    "    tip_y = [i for i in range(1,len(t.get_terminals())+ 1)]\n",
    "    ax1.scatter(x=tip_x, \n",
    "                y=tip_y, \n",
    "                s=2, \n",
    "                c=mug_dict[MUG_ATTR][\"hex_color\"][event_label],\n",
    "                label=\"\",)\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Lines\n",
    "\n",
    "    # Vertical lines for dates\n",
    "    for loc in ticks_dict[\"tick_locs\"]:\n",
    "        ax1.axvline(x=loc, color=\"darkgrey\", alpha=0.2, linewidth=0.75)\n",
    "\n",
    "        \n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.spines['bottom'].set_visible(True)\n",
    "    ax1.spines['left'].set_visible(False)\n",
    "    # --------------------------------------------\n",
    "    # Limits\n",
    "    date_range = np.max([n.numdate for n in t.get_terminals()]) - np.min([n.numdate for n in t.get_terminals()])\n",
    "    x_buffer = date_range * 0.1\n",
    "    y_buffer = math.ceil(len(t.get_terminals()) * 0.01)\n",
    "    # No left side x_buffer\n",
    "    ax1.set_xlim(ticks_dict[\"tick_locs\"][0], \n",
    "                 ticks_dict[\"tick_locs\"][-1] + x_buffer)\n",
    "    ax1.set_ylim(len(t.get_terminals()) + y_buffer, 0 - y_buffer,)\n",
    "\n",
    "    out_path = os.path.join(outdir, SCRIPT_NAME + \"_tree_{}.{}\".format(event_label.lower().replace(\" \",\"_\").replace(\".\",\"_\"), FMT))\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naked-adjustment",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Spread Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-birmingham",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for event_label in [list(subtree_dict.keys())[0]]:\n",
    "for event_label in subtree_dict:\n",
    "    \n",
    "    gdf = subtree_dict[event_label][\"gdf\"]\n",
    "    gdf_bezier = subtree_dict[event_label][\"gdf_bezier\"]\n",
    "    t = subtree_dict[event_label][\"node\"]\n",
    "\n",
    "    fig, ax1 = plt.subplots(1,\n",
    "                             dpi=dpi, \n",
    "                             figsize=figsize_mini,\n",
    "                             constrained_layout=True, \n",
    "                             )\n",
    "\n",
    "    world_polygons.plot(ax=ax1, \n",
    "                        zorder=1, \n",
    "                        alpha=0.5, \n",
    "                        color=\"grey\",\n",
    "                        edgecolor=\"white\", \n",
    "                        linewidth=0.25,\n",
    "                       )\n",
    "\n",
    "    gdf.plot( \n",
    "                color=subtree_dict[event_label][\"gdf_colors\"],\n",
    "                ax=ax1,\n",
    "                edgecolor=\"black\",\n",
    "                linewidths=0.5,\n",
    "                markersize=10,\n",
    "                zorder=3,\n",
    "                )\n",
    "    \n",
    "    \n",
    "    for curve_data in gdf_bezier:\n",
    "        # Line_color based on destination\n",
    "        dest_name = curve_data[1]\n",
    "        dest_conf = gdf_bezier[curve_data][\"conf\"]\n",
    "        curve = gdf_bezier[curve_data][\"curve\"]\n",
    "        line_color = hex_dict[tree_df[\"Mugration_\" + MUG_ATTR][dest_name]]\n",
    "        curve.plot(100, ax=ax1, color=line_color)\n",
    "               \n",
    "    \n",
    "    ax1.set_xlim(region_poly[event_label][\"xlim\"])\n",
    "    ax1.set_ylim(region_poly[event_label][\"ylim\"])\n",
    "    \n",
    "    ax1.set_xticks([])\n",
    "    ax1.set_yticks([])\n",
    "    \n",
    "    out_path = os.path.join(outdir, SCRIPT_NAME + \"_map_{}.{}\".format(event_label.lower().replace(\" \",\"_\").replace(\".\",\"_\"), FMT))\n",
    "    plt.savefig(out_path, dpi=dpi, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-evolution",
   "metadata": {},
   "source": [
    "---\n",
    "## Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-hypothesis",
   "metadata": {},
   "source": [
    "### Skyline plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "#treetime.wrappers.print_save_plot_skyline(tt, n_std=2.0, screen=True, save=False, plot=True)\n",
    "out_path_skyline_pdf = os.path.join(outdir, SCRIPT_NAME + \"_skyline.\" + FMT )\n",
    "out_path_skyline_txt = os.path.join(outdir, SCRIPT_NAME + \"_skyline.tsv\" )\n",
    "\n",
    "treetime.wrappers.print_save_plot_skyline(tt, \n",
    "                                          plot=out_path_skyline_pdf, \n",
    "                                          save=out_path_skyline_txt,\n",
    "                                          screen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-ownership",
   "metadata": {},
   "source": [
    "### Trees and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-antigua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tree dataframe with clock info\n",
    "out_path_df = os.path.join(outdir, SCRIPT_NAME + \".tsv\" )\n",
    "tree_df.to_csv(out_path_df, sep=\"\\t\")\n",
    "\n",
    "# Save timetree trees\n",
    "out_path_xml = os.path.join(outdir, SCRIPT_NAME + \".xml\" )\n",
    "out_path_nwk = os.path.join(outdir, SCRIPT_NAME + \".nwk\" )\n",
    "out_path_nexus = os.path.join(outdir, SCRIPT_NAME + \".nexus\" )\n",
    "Phylo.write(tt.tree, out_path_xml, 'phyloxml')\n",
    "Phylo.write(tt.tree, out_path_nwk, 'newick', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))\n",
    "Phylo.write(tt.tree, out_path_nexus, 'nexus', format_branch_length='%1.{}f'.format(BRANCH_LEN_SIG_DIG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-fountain",
   "metadata": {},
   "source": [
    "### JSON\n",
    "\n",
    "This can then be used for auspice via:\n",
    "\n",
    "```\n",
    "augur export v2 \\\n",
    "  --auspice-config auspice.config \\\n",
    "  --tree timetree.nwk \\\n",
    "  --node-data timetree.json \\\n",
    "  --output timetree_auspice.json \\\n",
    "  --lat-longs parse_tree_latlon.tsv \\\n",
    "  --color\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no alignment used\n",
    "node_data = {\"alignment\" : aln_path}\n",
    "node_data[\"input_tree\"] = tree_path\n",
    "\n",
    "node_data['clock'] = {'rate': tt.date2dist.clock_rate,\n",
    "                      'intercept': tt.date2dist.intercept,\n",
    "                      'rtt_Tmrca': -tt.date2dist.intercept/tt.date2dist.clock_rate}\n",
    "\n",
    "node_dict = {}\n",
    "\n",
    "# Iterate through all nodes in the tree\n",
    "for c in tree.find_clades():\n",
    "    # Add the node to the dictionary\n",
    "    node_dict[c.name] = {}\n",
    "    # Iterate through all attributes in the dataframe\n",
    "    for attr in tree_df.columns:\n",
    "        attr_val = tree_df[attr][c.name]\n",
    "        # Check if this attribute should be excluded\n",
    "        exclude = False\n",
    "        for keyword in COLOR_KEYWORD_EXCLUDE:\n",
    "            if keyword in attr.lower():\n",
    "                exclude = True    \n",
    "        if not exclude:           \n",
    "            # Fix numpy attr to float/int\n",
    "            if type(attr_val) == np.float64:\n",
    "                attr_val = float(attr_val)\n",
    "            elif type(attr_val) == np.int64:               \n",
    "                attr_val = int(attr_val)\n",
    "            # Make attribute name in dict lowercase (ex. Branch_Length -> branch_length)\n",
    "            node_dict[c.name][attr.lower()] = attr_val\n",
    "\n",
    "        \n",
    "# Add the dataframe information to the node dict for the json\n",
    "node_data[\"nodes\"] = node_dict\n",
    "\n",
    "out_path_json = os.path.join(outdir, SCRIPT_NAME + \".json\" )\n",
    "augur.utils.write_json(data=node_data, file_name=out_path_json, indent=2)\n",
    "\n",
    "\"\"\"for node in T.find_clades():\n",
    "    n_muts = len([\n",
    "        position\n",
    "        for ancestral, position, derived in node.mutations\n",
    "        if are_sequence_states_different(ancestral, derived)\n",
    "    ])\n",
    "\n",
    "    if args.timetree:\n",
    "        node_data['nodes'][node.name]['mutation_length'] = n_muts\n",
    "\n",
    "    node_data['nodes'][node.name]['branch_length'] = n_muts\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-geneva",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-endorsement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root to tip regression\n",
    "fig, (ax1) = plt.subplots(1, dpi=400, figsize=figsize_mini)\n",
    "\n",
    "# Plot tips\n",
    "df = tree_df[(tree_df[\"timetree_reg_x\"] != NO_DATA_CHAR) &\n",
    "                   (tree_df[\"Branch_Support_Color\"] == TERM_COL) ]\n",
    "tip_colors = []\n",
    "\n",
    "for attr in df[\"Mugration_\" + MUG_ATTR]:\n",
    "    tip_colors.append(hex_dict[attr])\n",
    "    \n",
    "ax1.scatter(data=df,\n",
    "               x=\"timetree_coord_x\", \n",
    "               y=\"timetree_coord_y\",\n",
    "               s=0.5, \n",
    "               c=tip_colors,\n",
    "               label=\"\",)\n",
    "\n",
    "ticks_dict = convert_timetree_ticks(tree=tt_copy.tree, step=500)\n",
    "ax1.set_xticklabels(ticks_dict[\"tick_labels\"])\n",
    "ax1.set_xticks(ticks_dict[\"tick_locs\"])\n",
    "\n",
    "date_to_x = (float(ticks_dict[\"tick_locs\"][-1]) - float(ticks_dict[\"tick_labels\"][-1]))\n",
    "\n",
    "tip_conf = []\n",
    "for rec in df.iterrows():\n",
    "    node_name = rec[0]\n",
    "    date_conf = df[\"timetree_\" + DATE_COL + \"_Confidence\"][node_name]\n",
    "    date_convert = [date_conf[0] + date_to_x, date_conf[1] + date_to_x ]\n",
    "    date_y = df[\"timetree_coord_y\"][node_name]\n",
    "    ax1.plot([date_convert[0], date_convert[1]], \n",
    "             [date_y,date_y],\n",
    "             linewidth=1,\n",
    "             alpha=1,\n",
    "             color=DISC_CMAPLIST[0],\n",
    "             zorder=3,\n",
    "            )\n",
    "\n",
    "Phylo.draw(tt_copy.tree, \n",
    "           axes=ax1, \n",
    "           show_confidence=False, \n",
    "           label_func = lambda x:'', \n",
    "           do_show=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-passenger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
