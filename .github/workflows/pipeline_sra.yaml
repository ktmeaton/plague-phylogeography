#------------------------------------------------------------------------------#
name: Pipeline SRA
#------------------------------------------------------------------------------#
# Global workflow environment variables
env:
    EAGER_CONDA_ENV: "nf-core-eager-2.2.0dev"
    EAGER_NF_REV: "7b51863957"
    PHYLO_CONDA_ENV: "plague-phylogeography-0.1.4dev"
    CONDA_ENVS_PATH: "/home/runner/miniconda/envs:/usr/share/miniconda/envs"
    CONDA_PKGS_DIRS: "/home/runner/miniconda/pkgs"
    GH_RESOURCES:    "--max_memory 6.GB --max_cpus 2"
#------------------------------------------------------------------------------#
# Workflow conditions
on:
  push:
    branches:
      - '*'
    paths:
      - '.github/workflows/pipeline_sra.yaml'
      - 'main.nf'
      - 'nextflow.config'
  pull_request:
    branches:
      - '*'
  release:
    types: [published]
#------------------------------------------------------------------------------#
jobs:
  #----------------------------------------------------------------------------#
  # Install dependencies
  install :
    runs-on: ubuntu-latest
    timeout-minutes: 120
    steps:
      #------------------------------------------------------------------------#
      # Install nextflow
      - name: install nextflow
        run: |
          wget -qO- get.nextflow.io | bash
          sudo mv nextflow /usr/local/bin/
      #------------------------------------------------------------------------#
      # download nextflow pipelines
      - name: download nf-core/eager
        shell: bash -l {0}
        run: |
          nextflow pull nf-core/eager
          nextflow pull nf-core/eager -r ${EAGER_NF_REV}
          nextflow run nf-core/eager -r ${EAGER_NF_REV} --help
          # Move env file into github workspace for hashing
          cp ~/.nextflow/assets/nf-core/eager/environment.yml \
            ./nf-core-eager.yaml

      - name: download plague-phylogeography
        shell: bash -l {0}
        run: |
          nextflow pull ${GITHUB_REPOSITORY}
          nextflow pull ${GITHUB_REPOSITORY} -r ${GITHUB_SHA}
          nextflow run ${GITHUB_REPOSITORY} --version
          # Move env files into github workspace for hashing
          cp ~/.nextflow/assets/${GITHUB_REPOSITORY}/environment.yaml \
            ./plague-phylogeography.yaml
      #------------------------------------------------------------------------#
      #  Restore (cache) conda environments
      - name: setup conda
        uses: goanpeca/setup-miniconda@v1

      - name: restore eager cache
        uses: actions/cache@v2
        id: eager-env-cache-restore
        with:
          path: |
            /home/runner/miniconda/envs/nf-core-eager-2.2.0dev
          key: eager-env-${{ runner.os }}-${{ hashFiles('./nf-core-eager.yaml') }}

      - name: restore plague-phylogeography cache
        uses: actions/cache@v2
        id: plague-phylogeography-env-cache-restore
        with:
          path: |
            /home/runner/miniconda/envs/plague-phylogeography-0.1.4dev
          key: plague-phylogeography-env-${{ runner.os }}-${{ hashFiles('./plague-phylogeography.yaml') }}
      #------------------------------------------------------------------------#
      # Check conda environments
      - name: check cache
        run: conda info --envs
      #  Fail workflows if cache not restored
      - name: fail eager cache
        if:  steps.eager-env-cache-restore.outputs.cache-hit != 'true'
        run: |
          echo "eager cache failed to load."
          echo "Try rerunning workflow after install workflow finishes."
          exit 1
      - name: fail plague-phylogeography cache
        if:  steps.plague-phylogeography-env-cache-restore.outputs.cache-hit != 'true'
        run: |
          echo "plague-phylogeography cache failed to load."
          echo "Try rerunning workflow after install workflow finishes."
          exit 1
      #------------------------------------------------------------------------#
      #  Download SRA Data
      - name: pipeline sra download
        if:  steps.plague-phylogeography-env-cache-restore.outputs.cache-hit == 'true' && steps.eager-env-cache-restore.outputs.cache-hit == 'true'
        shell: bash -l {0}
        run: |
          conda activate ${PHYLO_CONDA_ENV}
          nextflow run -r ${GITHUB_SHA} ${GITHUB_REPOSITORY} \
            --skip_assembly_download \
            --max_datasets_assembly 1 \
            --sqlite_select_command_sra "\"SELECT BioSampleAccession,SRARunAccession,SRALibraryLayout,SRAFileURL FROM Master WHERE (SRARunAccession = 'SRR1048902' OR SRARunAccession = 'SRR1048905')\"" \
            --max_datasets_sra 2 \
            --skip_eager \
            --skip_outgroup_download \
            --outdir test \
            ${GH_RESOURCES}
          conda deactivate
      #  SRA Analysis Pipeline
      - name: pipeline sra analysis
        if:  steps.plague-phylogeography-env-cache-restore.outputs.cache-hit == 'true' && steps.eager-env-cache-restore.outputs.cache-hit == 'true'
        shell: bash -l {0}
        run: |
          conda activate ${PHYLO_CONDA_ENV}
          nextflow run -r ${GITHUB_SHA} ${GITHUB_REPOSITORY} \
            --skip_assembly_download \
            --max_datasets_assembly 1 \
            --sqlite_select_command_sra "\"SELECT BioSampleAccession,SRARunAccession,SRALibraryLayout,SRAFileURL FROM Master WHERE (SRARunAccession = 'SRR1048902' OR SRARunAccession = 'SRR1048905')\"" \
            --max_datasets_sra 2 \
            --skip_outgroup_download \
            --outdir test \
            -resume \
            ${GH_RESOURCES}
          conda deactivate
